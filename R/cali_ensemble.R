#' Run Latin hypercube sampling atomized version
#' 
#' Run lake models using Latin hypercube sampling for model parameters.
#'
#' @param config_file filepath; to LakeEnsemblr yaml master config file
#' @param num integer; the number of random parameter sets to generate. If param file is provided
#' num = number of parameters in that file.
#' @param param_file filepath; to previously created parameter file set. If NULL creates a new
#' parameter set. Defaults to NULL
#' @param cmethod character; Method for calibration. Can be "LHC", "MCMC" or "". Defaults to "LHC"
#' @param obs_file filepath; to LakeEnsemblR standardised observed water temperature profile data.
#' If included adds observed data to netCDF and list if they are set to TRUE. Defaults to NULL.
#' @param config_file filepath; to LakeEnsemblr yaml master config file
#' @param model vector; model to export driving data. Options include c("GOTM", "GLM", "Simstrat",
#' "FLake")
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param spin_up numeric; Number of days to disregard as spin-up for analysis.
#' @param out_f character; name of the folder to store results into
#' @param qualfun function; function that calculates measure of fit from observed and simulated 
#'    variables, takes the two arguments Observed and Simulated
#' @param nout_fun integer; number of return values from qualfun
#' @param ... additional arguments passed to modFit or modMCMC. Only used when method is
#'    modFit or MCMC
#' @importFrom reshape2 dcast
#'
#' @examples
#' \dontrun{
#' 
#' config_file <- 'LakeEnsemblR.yaml'
#' 
#' cali_ensemble(config_file = config_file, num = 200, cmethod = "LCH",
#'              model = c("FLake", "GLM", "GOTM", "Simstrat", "MyLake"))
#'              
#' resMCMC <- cali_ensemble(config_file = config_file, num = 200, cmethod = "MCMC",
#'                          model = c("FLake", "GLM", "GOTM", "Simstrat", "MyLake"))
#'                
#' resMmodFit <- cali_ensemble(config_file = config_file, num = 200, cmethod = "modFit",
#'                             model = c("FLake", "GLM", "GOTM", "Simstrat", "MyLake"),
#'                             method = "Nelder-Mead")                                           
#'              
#' }
#' @importFrom FME Latinhyper
#' @importFrom FME modMCMC
#' @importFrom gotmtools get_yaml_value calc_cc input_nml sum_stat input_yaml get_vari
#' @importFrom glmtools get_nml_value
#' @importFrom reshape2 dcast
#' @importFrom FLakeR run_flake
#' @importFrom GLM3r run_glm
#' @importFrom GOTMr run_gotm
#' @importFrom SimstratR run_simstrat
#' @importFrom MyLakeR run_mylake
#' @importFrom lubridate round_date seconds_to_period
#' @importFrom configr read.config
#'
#' @export

cali_ensemble <- function(config_file, num = NULL, param_file = NULL, cmethod = "LHC",
                          qualfun = qual_meas, model = c("FLake", "GLM", "GOTM", "Simstrat"),
                          folder = ".", spin_up = NULL, out_f = "cali", nout_fun = 5, ...) {

##----------------- check inputs and set things up -------------------------------------------------  
  
  # check if method is one of the allowed
  if(!cmethod %in% c("modFit", "LHC", "MCMC")) {
    stop(paste0("Method ", cmethod, " not allowed. Use one of: modFit, LHC, or MCMC"))
  }
  
  # check model input
  model <- check_models(model)
  # check the master config file
  check_master_config(config_file, model)
  
  # It"s advisable to set timezone to GMT in order to avoid errors when reading time
  original_tz <- Sys.getenv("TZ")
  Sys.setenv(TZ = "GMT")
  tz <- "UTC"
  
  # Set working directory
  oldwd <- getwd()
  
  # this way if the function exits for any reason, success or failure, these are reset:
  on.exit({
    setwd(oldwd)
    Sys.setenv(TZ = original_tz)
  })
  
  
  # path to master config file
  yaml <- file.path(folder, config_file)
  # get setup parameter
  lat <- get_yaml_value(file = yaml, label = "location", key = "latitude")
  start <- get_yaml_value(file = yaml, label = "time", key = "start")
  stop <- get_yaml_value(file = yaml, label = "location", key = "stop")
  meteo_file <- get_yaml_value(file = yaml, label = "meteo", key = "file")
  obs_file <- get_yaml_value(file = yaml, label = "temperature", key = "file")
  time_unit <- get_yaml_value(config_file, "output", "time_unit")
  time_step <- get_yaml_value(config_file, "output", "time_step")
  cnfg_l <- lapply(model, function(m) get_yaml_value(config_file, "config_files", m))
  names(cnfg_l) <- model
  met_timestep <- get_meteo_time_step(file.path(folder,
                                                get_yaml_value(config_file, "meteo", "file")))
 
##----------------- read in observed data  ---------------------------------------------------------  
 
  # Create output time vector
  if(is.null(spin_up)){
    out_time <- seq.POSIXt(as.POSIXct(start, tz = tz), as.POSIXct(stop, tz = tz), by =
                             paste(time_step, time_unit))
  }else{
    start <- as.POSIXct(start, tz = tz) + spin_up * 24 * 60 * 60
    stop <- as.POSIXct(stop, tz = tz)
    out_time <- seq.POSIXt(as.POSIXct(start, tz = tz), as.POSIXct(stop, tz = tz), by =
                             paste(time_step, time_unit))
  }
  out_time <- data.frame(datetime = out_time)
  
  if(met_timestep == 86400){
    out_hour <- hour(start)
  }else{
    out_hour <- 0
  }
  
  # read in Observed data
  message("Loading observed wtemp data...")
  obs <- read.csv(file.path(folder, obs_file), stringsAsFactors = FALSE)
  obs$datetime <- as.POSIXct(obs$datetime, tz = tz)
  
  # Susbet to out_time
  obs <- obs[obs$datetime %in% out_time$datetime, ]
  
  obs_deps <- unique(obs$Depth_meter)
  
  # change data format from long to wide
  obs_out <- dcast(obs, datetime ~ Depth_meter, value.var = "Water_Temperature_celsius")
  str_depths <- colnames(obs_out)[2:ncol(obs_out)]
  colnames(obs_out) <- c("datetime", paste("wtr_", str_depths, sep = ""))
  obs_out$datetime <- as.POSIXct(obs_out$datetime)
  message("Finished!")
  
##---------------- read in  parameter initial values or create parameter sets ----------------------
  
  # if not existing create output file
  dir.create(file.path(folder, out_f), showWarnings = FALSE)
  # if cmethod == LHC sample parameter or read from provided file
  if(cmethod == "LHC") {
    if(is.null(param_file)) {
      param_file <- sample_LHC(config_file = config_file, num = num, method = "met",
                               folder = folder,
                               file.name = file.path(out_f, paste0("LHS_params_",
                                                                   format(Sys.time(),
                                                                          format = "%Y%m%d%H%M"))))
    }
    params <- read.csv(param_file, stringsAsFactors = FALSE)
    num <- nrow(params)
  } else {
    ## else use initial values from master config file as starting values
    # load master config file
    configr_master_config <- configr::read.config(file.path(folder, config_file))
    cal_section <- configr_master_config[["calibration"]][["met"]]
    params <- sapply(names(cal_section), function(n)cal_section[[n]]$initial)
    p_lower <- sapply(names(cal_section), function(n)cal_section[[n]]$lower)
    p_upper <- sapply(names(cal_section), function(n)cal_section[[n]]$upper)
  }

##--------- prepare models to be run ---------------------------------------------------------------  

  # prepare controll files of the models
  export_config(config_file = config_file, model = model, folder = folder)
  # prepare meteo files for the models
  export_meteo(config_file = config_file,model =  model,meteo_file =  meteo_file, folder = folder)
  # export initial conditions for each model
  export_init_cond(config_file = config_file, 
                   model = model,
                   print = TRUE)
  
##----------------- read in model meteo files ------------------------------------------------------
  
  ## read in meteo
  # read in meteo file
  mylake_met <- read.table(file.path(folder, "MyLake", "meteo_file.dat"), sep = "\t",
                           header = FALSE)
  ## list with long standard names
  l_names <- as.list(met_var_dic$standard_name)
  names(l_names) <- met_var_dic$short_name
  colnames(mylake_met) <- c(l_names$time, l_names$swr, l_names$cc, l_names$airt, l_names$relh,
                            l_names$p_surf, l_names$wind_speed, l_names$precip)
  # read in meteo file
  glm_met <- read.table(file.path(folder, "GLM", "meteo_file.csv"), sep = ",", header = TRUE)
  # read in meteo file
  flake_met <- read.table(file.path(folder, "FLake", "all_meteo_file.dat"), sep = "\t",
                          header = FALSE)
  colnames(flake_met) <- c("!Shortwave_Radiation_Downwelling_wattPerMeterSquared",
                           "Air_Temperature_celsius", "Vapor_Pressure_milliBar",
                           "Ten_Meter_Elevation_Wind_Speed_meterPerSecond",
                           "Cloud_Cover_decimalFraction", "datetime")
  # read in meteo file
  gotm_met <- read.table(file.path(folder, "GOTM", "meteo_file.dat"), sep = "\t", header = TRUE)
  colnames(gotm_met)[1] <- "!datetime"
  # read in meteo file
  simstrat_met <- read.table(file.path(folder, "Simstrat", "meteo_file.dat"), sep = "\t",
                             header = TRUE)
  # list with all meteo files
  met_l <- list(GLM = glm_met,
                GOTM = gotm_met,
                FLake = flake_met,
                Simstrat = simstrat_met,
                MyLake = mylake_met)
  
  ##------------------------- calibration ----------------------------------------------------------
  # method LCH
  if(cmethod == "LHC") {
    model_out <- setNames(
      lapply(model, function(mod_name) LHC_model(pars = params,
                                                 type = rep("met", (ncol(params)-1)),
                                                 model = mod_name, var = "temp",
                                                 config_file = config_file,
                                                 met = met_l[[mod_name]], folder = folder,
                                                 out_f = out_f, config_f = cnfg_l[[mod_name]],
                                                 obs_deps = obs_deps, obs_out = obs_out,
                                                 out_hour = out_hour, qualfun = qualfun,
                                                 nout_fun = 5
                                                )),
      model
    )
  }
  
  # method MCMC
  if(cmethod == "MCMC") {
    model_out <- setNames(
                lapply(model, function(m){
                    FME::modMCMC(f = wrap_model, p = params, par_name = names(params),
                                 type = rep("met",(length(params))),
                                 model = m,
                                 var = "temp",
                                 config_file = config_file,
                                 met = met_l[[m]],
                                 folder = folder,
                                 config_f = cnfg_l[[m]],
                                 out_f = out_f,  obs_deps = obs_deps, obs_out = obs_out,
                                 out_hour = out_hour,
                                 qualfun = function(O, P){
                                   ssr = sum((as.matrix(O[, -1]) - as.matrix(P[, -1]))^2)},
                                 out_name = paste0(cmethod, "_", m, "_",
                                                    format(Sys.time(), "%Y%m%d%H%M"),
                                                    ".csv"),
                                 niter = num, ...)}),
                model
    )
  }
  
  # method modFit
  if(cmethod == "modFit") {
    model_out <- setNames(
      lapply(model, function(m){
        FME::modFit(f = wrap_model, p = params, par_name = names(params),
                    type = rep("met",(length(params))),
                    model = m,
                    var = "temp",
                    config_file = config_file,
                    met = met_l[[m]],
                    folder = folder,
                    config_f = cnfg_l[[m]],
                    out_f = out_f,  obs_deps = obs_deps, obs_out = obs_out,
                    out_hour = out_hour,
                    qualfun = function(O, P){
                    res = as.vector(as.matrix(O[, -1]) - as.matrix(P[, -1]))},
                    out_name = "",
                    write = FALSE,
                    lower = p_lower,
                    upper = p_upper,
                    ...)}),
      model
    )
  }
  # return calibration results
  return(model_out)
}

##----------- wrapper function for LHC calibration -------------------------------------------------

LHC_model <- function(pars, type, model, var, config_file, met, folder, out_f,
                      obs_deps, obs_out, out_hour, qualfun, config_f, nout_fun) {
  
  # name of the output file to be written
  out_name <- paste0("LHC_", model, "_", format(Sys.time(), "%Y%m%d%H%M"), ".csv")
  # create the output folder, if not existing
  dir.create(file.path(folder, out_f), showWarnings = FALSE)
  # loop over all parameter sets
  for (p in seq_len(nrow(pars))) {
    # change the paremeter/meteo scaling
    change_pars(config_file = config_file, model = model, pars = pars[p, -ncol(pars)],
                type = type, met = met, folder = folder)
    # calculate quality measure
    qual_i <- cost_model(config_file = config_file, model = model, var = var, folder = folder,
                         obs_deps = obs_deps, obs_out = obs_out, out_hour = out_hour,
                         qualfun = qualfun, config_f = config_f)
    if(is.na(qual_i)) {
      qual_i <- rep(NA, nout_fun)
      out_i <- t(c(par_set = pars[p, ncol(pars)], qual_i))
    } else {
      # paste parameter values and quality measure
      out_i <- c(par_id = pars[p, ncol(pars)], qual_i)
    }
    # switch if file is existing
    flsw <- file.exists(file.path(folder, out_f, out_name))
    write.table(x = out_i, file = file.path(folder, out_f, out_name),
                append = ifelse(flsw, TRUE, FALSE), sep = ",", row.names = FALSE,
                col.names = ifelse(flsw, FALSE, TRUE), quote = FALSE)
    
  }
  
  message(paste0("\nFinished LHC for model: ", model, "\n"))
  
}

##----------------- warpper function for other two methods -----------------------------------------

wrap_model <- function(pars, type, model, var, config_file, met, folder, out_f,
                       obs_deps, obs_out, out_hour, qualfun, config_f, out_name,
                       par_name, write = TRUE) {
  # name of the parameter
  pars <- data.frame(matrix(pars, nrow = 1))
  colnames(pars) <- par_name

  # change the paremeter/meteo scaling
  change_pars(config_file = config_file, model = model, pars = pars,
              type = type, met = met, folder = folder)
  # calculate quality measure
  qual <- cost_model(config_file = config_file, model = model, var = var, folder = folder,
                     obs_deps = obs_deps, obs_out = obs_out, out_hour = out_hour,
                     qualfun = qualfun, config_f = config_f)
  if(is.na(qual)) {
    qual <- NA
    out_w <- t(c(pars, qual))
  } else {
    # paste parameter values and quality measure
    out_w <- data.frame(pars, qual = qual)
  }
  if(write) {
    # switch if file is existing
    flsw <- file.exists(file.path(folder, out_f, out_name))
    write.table(x = out_w, file = file.path(folder, out_f, out_name),
                append = ifelse(flsw, TRUE, FALSE), sep = ",", row.names = FALSE,
                col.names = ifelse(flsw, FALSE, TRUE), quote = FALSE)
  }
  # return
  return(qual)
}

##---------------------------------- utility functions ---------------------------------------------

#' Change parameter or meteo scaling for a model
#' 
#' Input a specific parameter or scale the meteorological forcing for a selected model
#' 
 
change_pars <- function(config_file, model, pars, type, met, folder) {
    
    if(length(pars) != length(type)) {
      stop(paste0("pars and type vectors need to have the same length"))
    }
    
    # get name of model config file
    config_f <- gotmtools::get_yaml_value(config_file, "config_files", model)
    # names of the parameters
    par_names <- names(pars)  
    # meteo pars  
    met_pars <- pars[type == "met"]
    # model specific pars
    model_pars <- pars[type == "model"]
    
    if (length(met_pars) > 0){
      if(model == "MyLake") {
        met_name <- "meteo_file.dat"
        } else {
        # get right lable and key for meteo file
        label <- dplyr::case_when(model == "GLM" ~ "meteorology",
                                  model == "GOTM" ~ "meteo",
                                  model == "FLake" ~ "METEO",
                                  model == "Simstrat" ~ "Input")
        key <- dplyr::case_when(model == "GLM" ~ "meteo_fl",
                                model == "GOTM" ~ "file",
                                model == "FLake" ~ "meteofile",
                                model == "Simstrat" ~ "Forcing")
        # get name of meteo file
        met_name <- get_config_value(model, config_f, label, key)
        }
      if (model == "FLake") {
        met_name <- gsub(",", "", met_name)
      }
      met_pars <- setNames(data.frame(met_pars), names(met_pars))
      # scale meteo
      scale_met(met = met, pars = met_pars, model = model,
                out_file = file.path(folder, model, met_name))
    }
    
    if (length(model_pars) > 0){
      
      for (i in seq_len(length(model_pars))) {
        # get right names for parameter
        label <- pars_dic$label[pars_dic$parname == names(model_pars)[i]]
        # get right names for parameter
        key <- pars_dic$key[pars_dic$parname == names(model_pars)[i]]
        # scale meteo
        suppressMessages(input_config_value(model = model, file = config_f, label = label,
                                            key = key,
                                            value = model_pars[i]))
      }
    }
    
  } 
  
  
#' Run a model and calculate model fit 
#' 
#' Runns the selected model and calculates fit metrics using a provided funtion
#' 

cost_model <- function(config_file, model, var, folder, obs_deps, obs_out, out_hour, qualfun,
                       config_f) {
  if(model == "FLake") {
    mod_arg <- list(sim_folder = file.path(folder, model),
                    nml_file =basename(config_f))
  } else if (model == "Simstrat") {
    mod_arg <- list(sim_folder = file.path(folder, model),
                    par_file = basename(config_f))
  } else if(model == "MyLake") {
    mod_arg <- list(sim_folder = file.path(folder),
                    config_dat = basename(config_f))
  } else {
    mod_arg <- list(sim_folder = file.path(folder, model))
  }
   ran <- FALSE
     tryCatch({
       invisible(do.call(paste0("run_", tolower(model)), mod_arg))
      ran <- TRUE
    }, error = function(e){})
   
    quali <- NA
    if(ran) {
      tryCatch({
        out <- get_output(config_file = config_file, model = model, var = var,
                          folder = folder, obs_depths = obs_deps, out_time = obs_out,
                          out_hour = out_hour)
        out <- as.data.frame(out)
        colnames(out) <- gsub(paste0(var, "."), "", colnames(out))
        # match depths
        depths <- as.numeric(gsub(".*wtr_", "", colnames(out)[-1]))
        id <- which(depths %in% obs_deps) + 1
        id_obs <- which(obs_deps %in% depths) + 1
        # match times
        out <- out[out$datetime %in% obs_out$datetime, c(1, id)]
        # calculate quality function
        quali <- qualfun(O = obs_out[obs_out$datetime %in% out$datetime, c(1, id_obs)],
                         P = out)
        
      }, error = function(e){})
    }
    
    return(quali)
    
  }



qual_meas <- function(O, P){
  
  # function that calculates different estimations for model accuracy, namely: root mean squared
  # error (rmse), (Nash-Sutcliff) model efficiency (nse), Pearson corelation coefficient (r),
  # relative error (re) and normalized mean absolute error (nmae)
  #
  # Arguments:
  #^^^^^^^^^^
  # O: observed values
  # P: predicted values
  #
  # Return Value:
  #^^^^^^^^^^^^^^
  # qual: A data.frame containing the five quality estimates
  O <- as.matrix(O[, -1])
  P <- as.matrix(P[, -1])
  
  # rmse
  rmse <- sqrt(mean((O - P)^2, na.rm = TRUE))
  
  
  # nash sutcliff
  nse <- 1 - sum((O - P)^2, na.rm = TRUE)/sum((O - mean(O, na.rm=TRUE))^2, na.rm = TRUE)
  
  # pearson corelation coef
  r <- sum((O - mean(O, na.rm = TRUE))*(P - mean(P, na.rm = TRUE)),
           na.rm = TRUE)/sqrt(sum((O - mean(O, na.rm = TRUE))^2, na.rm = TRUE)*
                                sum((P - mean(P, na.rm = TRUE))^2, na.rm = TRUE))
  
  # relative error
  re <- mean((P - O)/O, na.rm = TRUE)
  
  # normalised mean absolute error
  nmae <- mean(abs((O - P)/O), na.rm = TRUE)
  
  qual <- data.frame(rmse = rmse, nse = nse, r = r, re = re, nmae = nmae)
  
  return(qual)
}

