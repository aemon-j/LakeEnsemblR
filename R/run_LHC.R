#' Run Latin hypercube sampling
#'@description
#'Run lake models using Latin hypercube sampling for model parameters.
#'
#' @name run_LHC
#' @param parRange dataframe; the range (min, max) of the parameters, a data.frame with one row for each parameter, and two columns with the minimum (1st) and maximum (2nd) column.
#' @param num integer; the number of random parameter sets to generate.
#' @param param_file filepath; to previously created parameter file set. If NULL creates a new parameter set. Defaults to NULL
#' @param obs_file filepath; to LakeEnsemblR standardised observed water temperature profile data. If included adds observed data to netCDF and list if they are set to TRUE. Defaults to NULL.
#' @param config_file filepath; to LakeEnsemblr yaml master config file
#' @param model vector; model to export driving data. Options include c('GOTM', 'GLM', 'Simstrat', 'FLake')
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param meteo_file filepath; to met file which is in the standardised LakeEnsemblR format.
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#'
#' @examples
#' \dontrun{
#'pars <- c('wind_factor', 'swr_factor', 'lw_factor')
#'mat <- matrix(data = c(0.5,2,0.5,1.5,0.5,1.5), nrow = 3, byrow = T)
#'df <- as.data.frame(mat)
#'rownames(df) <- pars
#'run_LHC(parRange = parRange, num = 100, obs_file = 'LakeEnsemblR_wtemp_profile_standard.csv', config_file = 'Feeagh_master_config.yaml', model = 'FLake', meteo_file = 'LakeEnsemblR_meteo_standard.csv')
#' }
#'pars <- c('wind_factor', 'swr_factor', 'lw_factor')
#'mat <- matrix(data = c(0.5,2,0.5,1.5,0.5,1.5), nrow = 3, byrow = T)
#'df <- as.data.frame(mat)
#'rownames(df) <- pars
#'run_LHC(parRange = parRange, num = 100, obs_file = 'LakeEnsemblR_wtemp_profile_standard.csv', config_file = 'Feeagh_master_config.yaml', model = 'FLake', meteo_file = 'LakeEnsemblR_meteo_standard.csv')
#'@importFrom FME Latinhyper
#'
#' @export


run_LHC <- function(parRange, num, param_file = NULL, obs_file, config_file, model = c('GOTM', 'GLM', 'Simstrat', 'FLake'), meteo_file, folder = '.'){

  # It's advisable to set timezone to GMT in order to avoid errors when reading time
  original_tz = Sys.getenv("TZ")
  Sys.setenv(TZ="GMT")

  obs <- read.csv(obs_file, stringsAsFactors = FALSE)
  obs_deps <- unique(obs$Depth_meter)

  # change data format from long to wide
  obs_out <- reshape2::dcast(obs, datetime ~ Depth_meter, value.var = 'Water_Temperature_celsius')
  str_depths <- colnames(obs_out)[2:ncol(obs_out)]
  colnames(obs_out) <- c('datetime',paste('wtr_',str_depths, sep=""))
  obs_out$datetime <- as.POSIXct(obs_out$datetime)

  # get lat and lon - currently hack getting from GOTM but maybe could be in global config file?
  yaml = file.path(folder,config_file)

  # Function to be added to gotmtools
  lat <- get_yaml_value(file = yaml, label = 'location', key = 'latitude')
  lon <- get_yaml_value(file = yaml, label = 'location', key = 'longitude')
  start <- get_yaml_value(file = yaml, label = 'time', key = 'start')
  stop <- get_yaml_value(file = yaml, label = 'location', key = 'stop')

  obs <- obs[obs[,1] >= start & obs[,1] < stop,]


  ### Import data
  # I'd prefer to use a function that can read both comma and tab delimited. data.table::fread does this, but then it's data.table
  message('Loading met data...')
  met = read.csv(file.path(folder,meteo_file), stringsAsFactors = F)
  met[,1] <- as.POSIXct(met[,1])
  # Check time step
  tstep <- diff(as.numeric(met[,1]))

  if((mean(tstep) - 86400)/86400 < -0.05){
    daily = FALSE
    subdaily = TRUE
  } else {
    daily = TRUE
    subdaily = FALSE
  }


  ### Naming conventions standard input
  # Depending on the setup of the standard config file, we can omit reading exact titles and read column numbers
  colname_time = "datetime"
  colname_wind_speed = "Ten_Meter_Elevation_Wind_Speed_meterPerSecond"
  colname_wind_direction = "Ten_Meter_Elevation_Wind_Direction_degree"
  colname_air_temperature = "Air_Temperature_celsius"
  colname_dewpoint_temperature = "Dewpoint_Temperature_celsius"
  colname_relative_humidity = "Relative_Humidity_percent"
  colname_solar_radiation = "Shortwave_Radiation_Downwelling_wattPerMeterSquared"
  colname_longwave_radiation = "Longwave_Radiation_Downwelling_wattPerMeterSquared"
  colname_surface_pressure = "Surface_Level_Barometric_Pressure_pascal"
  colname_precipitation = "Precipitation_meterPerSecond"
  colname_snow = "Snowfall_meterPerDay"
  colname_vapour_pressure = "Vapor_Pressure_milliBar"
  colname_cloud_cover = "Cloud_Cover_decimalFraction"

  ### Check what met data is available, as this determines what model forcing option to use (in the simstrat config file)
  datetime = colname_time %in% colnames(met)
  wind_speed = colname_wind_speed %in% colnames(met)
  wind_direction = colname_wind_direction %in% colnames(met)
  air_temperature = colname_air_temperature %in% colnames(met)
  solar_radiation = colname_solar_radiation %in% colnames(met)
  vapour_pressure = colname_vapour_pressure %in% colnames(met)
  relative_humidity = colname_relative_humidity %in% colnames(met)
  longwave_radiation = colname_longwave_radiation %in% colnames(met)
  cloud_cover = colname_cloud_cover %in% colnames(met)
  # Availability of precipitation data only used for snow module
  precipitation = colname_precipitation %in% colnames(met)
  snowfall = colname_snow %in% colnames(met)

  if(is.null(param_file)){
    ## Create Latin hypercube sample of parameters
    par_names <- row.names(parRange)
    params <- Latinhyper(parRange = as.matrix(parRange), num = num)
    params <- signif(params, 4)
    colnames(params) <- par_names
    params <- as.data.frame(params)
    params$par_id <- paste0('p', formatC(1:nrow(params), width = 4, format = "d", flag = "0"))
    write.csv(params, file = file.path(folder, paste0('latin_hypercube_params_', paste0(model, collapse = '_'), '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)
  }else{
    params <- read.csv(param_file, stringsAsFactors = FALSE)
  }

  all_pars <- NULL

  # FLake
  #####
  if('FLake' %in% model){
    fla_met <- met

    # Humidity
    if(!vapour_pressure & relative_humidity){
      # Calculate vapour pressure as: relhum * saturated vapour pressure
      # Used formula for saturated vapour pressure from:
      # Woolway, R. I., Jones, I. D., Hamilton, D. P., Maberly, S. C., Muraoka, K., Read, J. S., . . . Winslow, L. A. (2015).
      # Automated calculation of surface energy fluxes with high-frequency lake buoy data.
      # Environmental Modelling & Software, 70, 191-198.

      fla_met[[colname_vapour_pressure]]=fla_met[[colname_relative_humidity]]/100 * 6.11 * exp(17.27 * fla_met[[colname_air_temperature]] / (237.3 + fla_met[[colname_air_temperature]]))

    }
    if(!cloud_cover){

      fla_met[[colname_cloud_cover]] =  gotmtools::calc_cc(date = fla_met$datetime,
                                                           airt = fla_met$Air_Temperature_celsius,
                                                           relh = fla_met$Relative_Humidity_percent,
                                                           swr = fla_met$Shortwave_Radiation_Downwelling_wattPerMeterSquared,
                                                           lat = lat, lon = lon,
                                                           elev = 14, # Needs to be added dynamically
                                                           daily = daily)

    }
    fla_met$index <- 1:nrow(fla_met)

    # Re-organise
    fla_met <- fla_met[,c('index','Shortwave_Radiation_Downwelling_wattPerMeterSquared','Air_Temperature_celsius', "Vapor_Pressure_milliBar", "Ten_Meter_Elevation_Wind_Speed_meterPerSecond", "Cloud_Cover_decimalFraction", "datetime")]
    fla_met$datetime <- format(fla_met$datetime, format = '%Y-%m-%d %H:%M:%S')
    colnames(fla_met)[1] <- paste0('!', colnames(fla_met)[1])

    # Select nml file for running FLake
    nml_file <- gotmtools::get_yaml_value(config_file, "config_files", "flake_config")
    nml_file <- file.path(folder, nml_file)
    # Select nml file again
    nml_file_run <- basename(gotmtools::get_yaml_value(config_file, "config_files", "flake_config"))

    mean_depth <- suppressWarnings(glmtools::get_nml_value(arg_name = 'depth_w_lk', nml_file = nml_file))
    depths <- seq(0,mean_depth,by = gotmtools::get_yaml_value(config_file,"model_settings", "output_depths"))


    depths <- obs_deps

    # Input values to nml
    nml_file <- list.files(file.path(folder, 'FLake'))[grep('nml', list.files(file.path(folder, 'FLake')))]
    nml_file <- file.path(folder, 'FLake', nml_file)

    input_nml(nml_file, 'SIMULATION_PARAMS', 'time_step_number', nrow(fla_met))
    input_nml(nml_file, 'METEO', 'meteofile', paste0("'",'temp_meteo_file.dat',"'"))

    for(i in 1:nrow(params)){
      fla_met2 <- fla_met
      fla_met2$Ten_Meter_Elevation_Wind_Speed_meterPerSecond <- fla_met2$Ten_Meter_Elevation_Wind_Speed_meterPerSecond * params$wind_factor[i]
      fla_met2$Shortwave_Radiation_Downwelling_wattPerMeterSquared <- fla_met2$Shortwave_Radiation_Downwelling_wattPerMeterSquared * params$swr_factor[i]

      # Write to file
      write.table(fla_met2, file.path(folder, 'FLake', 'temp_meteo_file.dat'), sep = '\t', quote = FALSE, col.names = FALSE, row.names = FALSE)


      run_flake(sim_folder = file.path(folder, 'FLake'), nml_file = nml_file_run)

      # Extract output
      # Add in obs depths which are not in depths and less than mean depth

      fla_out <- get_wtemp_df(output = file.path(folder, 'FLake', 'output', 'output.dat'), depths = depths, folder = 'FLake', nml_file = nml_file, long = TRUE)
      stats <- sum_stat(fla_out, obs, depth = TRUE)
      stats$par_id <- params$par_id[i]

      if(i == 1){
        out_stats <- stats
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
      }
      print(paste0('[',i,'/', nrow(params),']'))
    }

    write.csv(out_stats, file.path(folder, 'Flake', 'output', paste0('latin_hypercube_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

    out_stats$model <- 'FLake'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }





    message('FLake: Finished Latin Hypercube Sampling calibration')


  }

  # GLM
  #####
  if('GLM' %in% model){
    glm_met <- met

    # Convert units
    glm_met$Precipitation_meterPerDay <- glm_met$Precipitation_meterPerSecond * 86400

    # Subset data
    glm_met <- glm_met[,c('datetime','Shortwave_Radiation_Downwelling_wattPerMeterSquared', "Longwave_Radiation_Downwelling_wattPerMeterSquared", 'Air_Temperature_celsius', 'Relative_Humidity_percent', "Ten_Meter_Elevation_Wind_Speed_meterPerSecond", "Precipitation_meterPerDay", "Snowfall_meterPerDay")]

    colnames(glm_met) <- c('Date','ShortWave','LongWave','AirTemp','RelHum','WindSpeed','Rain','Snow')
    glm_met[,1] <- format(glm_met[,1], format = '%Y-%m-%d %H:%M:%S')

    if("LongWave" %in% colnames(glm_met)){
      lw_type = 'LW_IN'
    }else{
      lw_type = 'LW_IN' ### Needs to be developed catch if no LW
    }

    # Input to nml file
    nml_path <- file.path(folder, gotmtools::get_yaml_value(config_file, "config_files", "glm_config"))
    nml <- glmtools::read_nml(nml_path)

    nml_list <- list('subdaily' = subdaily, 'lw_type' = lw_type, 'meteo_fl' = 'temp_meteo_file.csv')
    nml <- glmtools::set_nml(nml, arg_list = nml_list)

    glmtools::write_nml(nml, nml_path)

    # Input values to nml
    nml_file <- file.path(folder, 'GLM', 'glm3.nml')

    input_nml(nml_file, 'meteorology', 'meteo_fl', paste0("'",'temp_meteo_file.csv',"'"))

    # Get depths for comparison
    depths <- obs_deps

    for(i in 1:nrow(params)){
      glm_met2 <- glm_met
      glm_met2$WindSpeed <- glm_met2$WindSpeed * params$wind_factor[i]
      glm_met2$ShortWave <- glm_met2$ShortWave * params$swr_factor[i]
      glm_met2$LongWave <- glm_met2$LongWave * params$lw_factor[i]

      # Write to file
      write.csv(glm_met2, file.path(folder, 'GLM', 'temp_meteo_file.csv'), quote = FALSE, row.names = FALSE)


      run_glm(sim_folder = file.path(folder, 'GLM'))

      # Extract output
      # Add in obs depths which are not in depths and less than mean depth

      # Extract output
      glm_out <- glmtools::get_var(file = file.path(folder, 'GLM', 'output', 'output.nc'), var_name = 'temp', reference = 'surface', z_out = depths)

      glm_out <- reshape2::melt(glm_out, id.vars = 1)
      glm_out[,2] <- as.character(glm_out[,2])
      glm_out[,2] <- as.numeric(gsub('temp_','',glm_out[,2]))
      colnames(glm_out) <- c('datetime','Depth_meter','Water_Temperature_celsius')

      stats <- sum_stat(glm_out, obs, depth = TRUE)
      stats$par_id <- params$par_id[i]

      if(i == 1){
        out_stats <- stats
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
      }
      print(paste0('[',i,'/', nrow(params),']'))
    }

    write.csv(out_stats, file.path(folder, 'GLM', 'output', paste0('latin_hypercube_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

    out_stats$model <- 'GLM'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }





    message('GLM: Finished Latin Hypercube Sampling calibration')



  }

  ## GOTM
  if('GOTM' %in% model){
    met_got <- met
    yaml = file.path(folder,gotmtools::get_yaml_value(config_file, "config_files", "gotm_config"))

    met_outfile <- 'meteo_file_temp.dat'

    # Function to be added to gotmtools
    lat <- get_yaml_value(file = yaml, label = 'location', key = 'latitude')
    lon <- get_yaml_value(file = yaml, label = 'location', key = 'longitude')

    if(wind_direction){
      direction=270-met_got[[colname_wind_direction]] # Converting the wind direction to the "math" direction
      rads=direction/180*pi
      xcomp=met_got[[colname_wind_speed]]*cos(rads)
      ycomp=met_got[[colname_wind_speed]]*sin(rads)
      met_got$Uwind = xcomp
      met_got$Vwind = ycomp
    }else{
      met_got$Uwind_meterPerSecond = met_got[[colname_wind_speed]]
      met_got$Vwind_meterPerSecond = 0
    }

    if(!cloud_cover){
      # Function from gotmtools

      met_got$Cloud_Cover_decimalFraction <- gotmtools::calc_cc(date = met_got$datetime, airt = met_got$Air_Temperature_celsius, relh = met_got$Relative_Humidity_percent, swr = met_got$Shortwave_Radiation_Downwelling_wattPerMeterSquared, lat = lat, lon = lon,
                                                                elev = 14, # Needs to be dynamically added
                                                                daily = daily)
    }

    met_got <- met_got[,c('datetime', 'Uwind_meterPerSecond', 'Vwind_meterPerSecond', 'Surface_Level_Barometric_Pressure_pascal', 'Air_Temperature_celsius', 'Relative_Humidity_percent', 'Cloud_Cover_decimalFraction', 'Shortwave_Radiation_Downwelling_wattPerMeterSquared', 'Precipitation_meterPerSecond')]

    colnames(met_got)[1] <- paste0('!', colnames(met_got)[1])
    met_got[,1] <- format(met_got[,1], '%Y-%m-%d %H:%M:%S')

    #Reduce number of digits
    met_got[,-1] <- signif(met_got[,-1], digits = 8)



    # Format gotm.yaml file
    ## Set gotm.yaml met config
    ######
    #u10
    gotmtools::input_yaml(file = yaml, label = 'u10', key = 'file', value = met_outfile)
    gotmtools::input_yaml(file = yaml, label = 'u10', key = 'column', value = (which(colnames(met_got) == "Uwind_meterPerSecond")-1))
    gotmtools::input_yaml(file = yaml, label = 'u10', key = 'scale_factor', value = 1)
    #v10
    gotmtools::input_yaml(file = yaml, label = 'v10', key = 'file', value = met_outfile)
    gotmtools::input_yaml(file = yaml, label = 'v10', key = 'column', value = (which(colnames(met_got) == "Vwind_meterPerSecond")-1))
    gotmtools::input_yaml(file = yaml, label = 'v10', key = 'scale_factor', value = 1)
    #airp
    gotmtools::input_yaml(file = yaml, label = 'airp', key = 'file', value = met_outfile)
    gotmtools::input_yaml(file = yaml, label = 'airp', key = 'column', value = (which(colnames(met_got) == "Surface_Level_Barometric_Pressure_pascal" )-1))
    gotmtools::input_yaml(file = yaml, label = 'airp', key = 'scale_factor', value = 1)
    #airt
    gotmtools::input_yaml(file = yaml, label = 'airt', key = 'file', value = met_outfile)
    gotmtools::input_yaml(file = yaml, label = 'airt', key = 'column', value = (which(colnames(met_got) == "Air_Temperature_celsius")-1))
    gotmtools::input_yaml(file = yaml, label = 'airt', key = 'scale_factor', value = 1)
    #cloud
    gotmtools::input_yaml(file = yaml, label = 'cloud', key = 'file', value = met_outfile)
    gotmtools::input_yaml(file = yaml, label = 'cloud', key = 'column', value = (which(colnames(met_got) == "Cloud_Cover_decimalFraction" )-1))
    gotmtools::input_yaml(file = yaml, label = 'cloud', key = 'scale_factor', value = 1)
    #swr
    gotmtools::input_yaml(file = yaml, label = 'swr', key = 'file', value = met_outfile)
    gotmtools::input_yaml(file = yaml, label = 'swr', key = 'column', value = (which(colnames(met_got) == "Shortwave_Radiation_Downwelling_wattPerMeterSquared")-1))
    gotmtools::input_yaml(file = yaml, label = 'swr', key = 'scale_factor', value = 1)
    #precip
    gotmtools::input_yaml(file = yaml, label = 'precip', key = 'file', value = met_outfile)
    gotmtools::input_yaml(file = yaml, label = 'precip', key = 'column', value = (which(colnames(met_got) == "Precipitation_meterPerSecond")-1))
    gotmtools::input_yaml(file = yaml, label = 'precip', key = 'scale_factor', value = 1)
    if("Relative_Humidity_percent" %in% colnames(met_got)){
      #hum
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'file', value = met_outfile)
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'column', value = (which(colnames(met_got) == "Relative_Humidity_percent")-1))
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'type', value = 1) #1=relative humidity (%), 2=wet-bulb temperature, 3=dew point temperature, 4=specific humidity (kg/kg)
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'scale_factor', value = 1)
    }
    if("Dewpoint_Temperature_celsius" %in% colnames(met_got)){
      #hum
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'file', value = met_outfile)
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'column', value = (which(colnames(met_got) == "Dewpoint_Temperature_celsius")-1))
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'type', value = 3) #1=relative humidity (%), 2=wet-bulb temperature, 3=dew point temperature, 4=specific humidity (kg/kg)
      gotmtools::input_yaml(file = yaml, label = 'hum', key = 'scale_factor', value = 1)
    }

    # Get depths for comparison
    depths = -obs_deps
    obs_got <- obs
    obs_got[,2] <- -obs_got[,2]

    for(i in 1:nrow(params)){
      got_met2 <- met_got
      got_met2$Uwind_meterPerSecond <- got_met2$Uwind_meterPerSecond * params$wind_factor[i]
      got_met2$Vwind_meterPerSecond <- got_met2$Vwind_meterPerSecond * params$wind_factor[i]
      got_met2$Shortwave_Radiation_Downwelling_wattPerMeterSquared <- got_met2$Shortwave_Radiation_Downwelling_wattPerMeterSquared * params$swr_factor[i]

      # Write to file
      write.table(got_met2, file.path('GOTM', met_outfile), quote = FALSE, row.names = FALSE, sep = '\t', col.names = TRUE)

      yaml_file <- file.path(folder, gotmtools::get_yaml_value(config_file, "config_files", "gotm_config"))

      run_gotm(sim_folder = file.path(folder, 'GOTM'), yaml_file = basename(yaml_file))

      # Extract output
      # Add in obs depths which are not in depths and less than mean depth

      # Extract output
      temp <- gotmtools::get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'temp', print = FALSE)
      z <- gotmtools::get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'z', print = FALSE)


      got_out <- setmodDepths(temp, z, depths = depths, print = T)
      colnames(got_out) <- c('datetime','Depth_meter','Water_Temperature_celsius')

      stats <- sum_stat(got_out, obs_got, depth = TRUE)
      stats$par_id <- params$par_id[i]

      if(i == 1){
        out_stats <- stats
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
      }
      print(paste0('[',i,'/', nrow(params),']'))
    }

    write.csv(out_stats, file.path(folder, 'GOTM', 'output', paste0('latin_hypercube_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

    out_stats$model <- 'GOTM'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }



    message('GOTM: Finished Latin Hypercube Sampling calibration')

  }

  ## Simstrat
  if('Simstrat' %in% model){
    par_file <- file.path(folder,gotmtools::get_yaml_value(config_file, "config_files", "simstrat_config"))
    met_sim <- met
    met_outfile <- 'meteo_file_temp.dat'

    # Required input file changes depending on the forcing mode in the config file
    forcing_mode <- get_json_value(par_file, "ModelConfig", "Forcing")

    ### Pre-processing
    # Time
    if(datetime){
      # Time in simstrat is in decimal days since a defined start year
      start_year <- get_json_value(par_file, "Simulation", "Start year")

      met_sim$datetime = as.numeric(difftime(met_sim$datetime,as.POSIXct(paste0(start_year,"-01-01")),units = "days"))
    }else{
      stop("Cannot find \"datetime\" column in the input file. Without this column, the model cannot run")
    }

    # Wind
    # If wind direction is provided, U and V wind components are calculated. If not, V wind is set to 0
    if(wind_direction){
      direction=270-met_sim[[colname_wind_direction]] # Converting the wind direction to the "math" direction
      rads=direction/180*pi
      xcomp=met_sim[[colname_wind_speed]]*cos(rads)
      ycomp=met_sim[[colname_wind_speed]]*sin(rads)
      met_sim$Uwind = xcomp
      met_sim$Vwind = ycomp
    }else{
      met_sim$Uwind_meterPerSecond = met_sim[[colname_wind_speed]]
      met_sim$Vwind_meterPerSecond = 0
    }

    # Humidity
    if(!vapour_pressure & relative_humidity){
      # Calculate vapour pressure as: relhum * saturated vapour pressure
      # Used formula for saturated vapour pressure from:
      # Woolway, R. I., Jones, I. D., Hamilton, D. P., Maberly, S. C., Muraoka, K., Read, J. S., . . . Winslow, L. A. (2015).
      # Automated calculation of surface energy fluxes with high-frequency lake buoy data.
      # Environmental Modelling & Software, 70, 191-198.

      met_sim[[colname_vapour_pressure]]=met_sim[[colname_relative_humidity]]/100 * 6.11 * exp(17.27 * met_sim[[colname_air_temperature]] / (237.3 + met_sim[[colname_air_temperature]]))

    }

    # If snow_module is true, there needs to be a precipitation (or snowfall) columnn.
    snow_module <- get_json_value(par_file, "ModelConfig", "SnowModel") == 1
    # Optionally, if there is no precipitation/snowfall column, we can set the snow_module to FALSE

    if(snow_module & !(precipitation | snowfall)){
      stop("There is no precipitation data and the Simstrat snow_module is set to TRUE.")
    }


    # Precipitation
    # Precipitation needs to be in m h-1: 1 m s-1 = 3600 m h-1, or 1 m d-1 = 1/24 m h-1
    if(precipitation){
      met_sim$`Precipitation_meterPerHour`=met_sim[[colname_precipitation]]*3600
    }else if(snowfall){
      met_sim$`Precipitation_meterPerHour`=met_sim[[colname_snow]]/24
    }




    ### Build simstrat_forcing file
    # Boolean to see if there is enough data to write the meteo file
    enoughData=T


    # Now build the simstrat forcing file, based on the forcing_mode. If data is not available, an error message is displayed
    if(forcing_mode == "5"){
      if(!(wind_speed & air_temperature & solar_radiation & (vapour_pressure | relative_humidity) & longwave_radiation)){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation, colname_vapour_pressure,
                                       colname_longwave_radiation)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }else if(forcing_mode == "4"){
      # Forcing mode 4 requires one column with "heat flux" input. LakeEnsemblR does not yet have functionality for this option
      enoughData = F
    }else if(forcing_mode == "3"){
      if(!(wind_speed & air_temperature & solar_radiation & (vapour_pressure | relative_humidity) & cloud_cover)){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation, colname_vapour_pressure,
                                       colname_cloud_cover)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }else if(forcing_mode == "2"){
      if(!(wind_speed & air_temperature & solar_radiation & (vapour_pressure | relative_humidity))){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation, colname_vapour_pressure)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }else if(forcing_mode == "1"){
      if(!(wind_speed & air_temperature & solar_radiation)){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }

    if(!enoughData){stop(paste("There is no data to run the model in forcing mode",forcing_mode))}

    input_json(file = par_file, label = 'Input', key = 'Forcing', paste0('"', met_outfile, '"'))

    # Need to input start and stop into json par file
    par_file <- file.path(folder, gotmtools::get_yaml_value(config_file, "config_files", "simstrat_config"))
    timestep <- get_json_value(par_file, "Simulation", "Timestep s")
    reference_year <- get_json_value(par_file, "Simulation", "Start year")

    # par file for running Simstrat
    par_file <- basename(gotmtools::get_yaml_value(config_file, "config_files", "simstrat_config"))


    for(i in 1:nrow(params)){
      sim_met2 <- simstrat_forcing
      sim_met2$Uwind_meterPerSecond <- sim_met2$Uwind_meterPerSecond * params$wind_factor[i]
      sim_met2$Vwind_meterPerSecond <- sim_met2$Vwind_meterPerSecond * params$wind_factor[i]
      sim_met2$Shortwave_Radiation_Downwelling_wattPerMeterSquared <- sim_met2$Shortwave_Radiation_Downwelling_wattPerMeterSquared * params$swr_factor[i]
      sim_met2$Longwave_Radiation_Downwelling_wattPerMeterSquared <- sim_met2$Longwave_Radiation_Downwelling_wattPerMeterSquared * params$lw_factor[i]

      # Write to file
      write.table(sim_met2, file = file.path(folder,"Simstrat", met_outfile),sep = "\t",quote = F,row.names = F)

      run_simstrat(sim_folder = file.path(folder, 'Simstrat'), par_file = par_file, verbose = FALSE)

      ### Extract output
      sim_out <- read.table(file.path(folder, "Simstrat", "output", "T_out.dat"), header = T, sep=",", check.names = F)

      ### Convert decimal days to yyyy-mm-dd HH:MM:SS


      sim_out[,1] <- as.POSIXct(sim_out[,1]*3600*24, origin = paste0(reference_year,"-01-01"))
      # In case sub-hourly time steps are used, rounding might be necessary
      sim_out[,1] <- lubridate::round_date(sim_out[,1], unit = lubridate::seconds_to_period(timestep))

      # First column datetime, then depth from shallow to deep
      sim_out <- sim_out[,c(1,ncol(sim_out):2)]

      # Remove columns without any value
      sim_out <- sim_out[,colSums(is.na(sim_out))<nrow(sim_out)]
      mod_depths = as.numeric(colnames(sim_out)[-1])

      sim_depths <- -obs_deps
      message('Interpolating Simstrat temp to include obs depths')

      # Create empty matrix and interpolate to new depths
      wat_mat <- matrix(NA, nrow = nrow(sim_out), ncol = length(sim_depths))
      for(j in 1:nrow(sim_out)){
        y = as.vector(unlist(sim_out[j,-1]))
        wat_mat[j,] <- approx(mod_depths, y, sim_depths, rule = 2)$y
      }
      df = data.frame(wat_mat)
      df$datetime <- sim_out[,1]
      df <- df[,c(ncol(df), 1:(ncol(df)-1))]
      colnames(df) <- c("datetime", paste0('wtr_',abs(sim_depths)))
      sim_out <- df


      sim_out <- reshape2::melt(sim_out, id.vars = 1)
      sim_out[,2] <- as.character(sim_out[,2])
      sim_out[,2] <- as.numeric(gsub('wtr_','',sim_out[,2]))
      colnames(sim_out) <- c('datetime','Depth_meter','Water_Temperature_celsius')

      stats <- sum_stat(sim_out, obs, depth = TRUE)
      stats$par_id <- params$par_id[i]

      if(i == 1){
        out_stats <- stats
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
      }


      print(paste0('[',i,'/', nrow(params),']'))
    }




    ### Write the table in the present working directory
    write.csv(out_stats, file.path(folder, 'Simstrat', 'output', paste0('latin_hypercube_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

    out_stats$model <- 'Simstrat'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }

    message('Simstrat: Finished Latin Hypercube Sampling calibration')
  }

  dir.create(file.path(folder,'output'), showWarnings = FALSE)

  write.csv(all_pars, file.path(folder,'output', paste0('LHC_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

}


