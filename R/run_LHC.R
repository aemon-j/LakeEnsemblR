#' Run Latin hypercube sampling
#'@description
#'Run lake models using Latin hypercube sampling for model parameters.
#'
#' @name run_LHC
#' @param parRange dataframe; the range (min, max) of the parameters, a data.frame with one row for each parameter, and two columns with the minimum (1st) and maximum (2nd) column.
#' @param num integer; the number of random parameter sets to generate. If param file is provided num = number of parameters in that file.
#' @param param_file filepath; to previously created parameter file set. If NULL creates a new parameter set. Defaults to NULL
#' @param obs_file filepath; to LakeEnsemblR standardised observed water temperature profile data. If included adds observed data to netCDF and list if they are set to TRUE. Defaults to NULL.
#' @param config_file filepath; to LakeEnsemblr yaml master config file
#' @param model vector; model to export driving data. Options include c('GOTM', 'GLM', 'Simstrat', 'FLake')
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param meteo_file filepath; to met file which is in the standardised LakeEnsemblR format.
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#'
#' @examples
#' \dontrun{
#'pars <- c('wind_factor', 'swr_factor', 'lw_factor')
#'mat <- matrix(data = c(0.5,2,0.5,1.5,0.5,1.5), nrow = 3, byrow = T)
#'df <- as.data.frame(mat)
#'rownames(df) <- pars
#'run_LHC(parRange = parRange, num = 100, obs_file = 'LakeEnsemblR_wtemp_profile_standard.csv', config_file = 'Feeagh_master_config.yaml', model = 'FLake', meteo_file = 'LakeEnsemblR_meteo_standard.csv')
#' }
#'pars <- c('wind_factor', 'swr_factor', 'lw_factor')
#'mat <- matrix(data = c(0.5,2,0.5,1.5,0.5,1.5), nrow = 3, byrow = T)
#'df <- as.data.frame(mat)
#'rownames(df) <- pars
#'run_LHC(parRange = parRange, num = 100, obs_file = 'LakeEnsemblR_wtemp_profile_standard.csv', config_file = 'Feeagh_master_config.yaml', model = 'FLake', meteo_file = 'LakeEnsemblR_meteo_standard.csv')
#'@importFrom FME Latinhyper
#'@importFrom gotmtools get_yaml_value calc_cc input_nml sum_stat input_yaml get_vari
#'@importFrom glmtools get_nml_value
#'@importFrom reshape2 dcast
#'@importFrom FLakeR run_flake
#'@importFrom GLM3r run_glm
#'@importFrom GOTMr run_gotm
#'@importFrom SimstratR run_simstrat
#'@importFrom lubridate round_date seconds_to_period
#'
#' @export


run_LHC <- function(parRange, num = NULL, param_file = NULL, obs_file, config_file,
                    model = c('GOTM', 'GLM', 'Simstrat', 'FLake'), meteo_file, folder = '.'){

  # It's advisable to set timezone to GMT in order to avoid errors when reading time
  original_tz = Sys.getenv("TZ")
  Sys.setenv(TZ="GMT")

  obs <- read.csv(file.path(folder, obs_file), stringsAsFactors = FALSE)
  obs_deps <- unique(obs$Depth_meter)

  # change data format from long to wide
  obs_out <- dcast(obs, datetime ~ Depth_meter, value.var = 'Water_Temperature_celsius')
  str_depths <- colnames(obs_out)[2:ncol(obs_out)]
  colnames(obs_out) <- c('datetime',paste('wtr_',str_depths, sep=""))
  obs_out$datetime <- as.POSIXct(obs_out$datetime)

  # get lat and lon from global config file
  yaml = file.path(folder,config_file)

  # Function to be added to gotmtools
  lat <- get_yaml_value(file = yaml, label = 'location', key = 'latitude')
  lon <- get_yaml_value(file = yaml, label = 'location', key = 'longitude')
  depth <- get_yaml_value(file = yaml, label = 'location', key = 'depth')
  start <- as.POSIXct(get_yaml_value(file = yaml, label = 'time', key = 'start'))
  stop <- as.POSIXct(get_yaml_value(file = yaml, label = 'location', key = 'stop'))

  obs <- obs[obs[,1] >= start & obs[,1] < stop,]

  # Which hemisphere?
  if(lat > 0){
    NH = TRUE
  }else{
    NH = FALSE
  }


  ### Import data
  # I'd prefer to use a function that can read both comma and tab delimited.
  # data.table::fread does this, but then it's data.table
  message('Loading met data...')
  met = read.csv(file.path(folder,meteo_file), stringsAsFactors = F)
  met[,1] <- as.POSIXct(met[,1])
  # Check time step
  tstep <- diff(as.numeric(met[,1]))

  if((mean(tstep) - 86400)/86400 < -0.05){
    daily = FALSE
    subdaily = TRUE
  } else {
    daily = TRUE
    subdaily = FALSE
  }


  ### Naming conventions standard input
  # Depending on the setup of the standard config file, we can omit reading exact titles and read column numbers
  colname_time = "datetime"
  colname_wind_speed = "Ten_Meter_Elevation_Wind_Speed_meterPerSecond"
  colname_wind_direction = "Ten_Meter_Elevation_Wind_Direction_degree"
  colname_air_temperature = "Air_Temperature_celsius"
  colname_dewpoint_temperature = "Dewpoint_Temperature_celsius"
  colname_relative_humidity = "Relative_Humidity_percent"
  colname_solar_radiation = "Shortwave_Radiation_Downwelling_wattPerMeterSquared"
  colname_longwave_radiation = "Longwave_Radiation_Downwelling_wattPerMeterSquared"
  colname_surface_pressure = "Surface_Level_Barometric_Pressure_pascal"
  colname_precipitation = "Precipitation_meterPerSecond"
  colname_snow = "Snowfall_meterPerDay"
  colname_vapour_pressure = "Vapor_Pressure_milliBar"
  colname_cloud_cover = "Cloud_Cover_decimalFraction"

  ### Check what met data is available, as this determines what model forcing option to use (in the simstrat config file)
  datetime = colname_time %in% colnames(met)
  wind_speed = colname_wind_speed %in% colnames(met)
  wind_direction = colname_wind_direction %in% colnames(met)
  air_temperature = colname_air_temperature %in% colnames(met)
  solar_radiation = colname_solar_radiation %in% colnames(met)
  vapour_pressure = colname_vapour_pressure %in% colnames(met)
  relative_humidity = colname_relative_humidity %in% colnames(met)
  longwave_radiation = colname_longwave_radiation %in% colnames(met)
  cloud_cover = colname_cloud_cover %in% colnames(met)
  # Availability of precipitation data only used for snow module
  precipitation = colname_precipitation %in% colnames(met)
  snowfall = colname_snow %in% colnames(met)

  ## read parameter and limits from yaml file
  par_sw <- tryCatch({par_names <- get_yaml_value(file = yaml, label = 'caliLHS', key = 'parameter')
  par_upper <- get_yaml_value(file = yaml, label = 'caliLHS', key = 'upper')
  par_lower <- get_yaml_value(file = yaml, label = 'caliLHS', key = 'lower')
  GOTM_names <- get_yaml_value(file = yaml, label = 'caliLHS', key = 'name_GOTM')
  GLM_names <- get_yaml_value(file = yaml, label = 'caliLHS', key = 'name_GLM')
  Simstrat_names <- get_yaml_value(file = yaml, label = 'caliLHS', key = 'name_Simstrat')
  FLake_names <- get_yaml_value(file = yaml, label = 'caliLHS', key = 'name_FLake')
  TRUE},
  error = function(e)return(FALSE))

  meteo_sw <- tryCatch({
  meteo_names <- get_yaml_value(file = yaml, label = 'meteoLHS', key = 'vars')
  meteo_upper <- get_yaml_value(file = yaml, label = 'meteoLHS', key = 'upper')
  meteo_lower <- get_yaml_value(file = yaml, label = 'meteoLHS', key = 'lower')
  TRUE},
  error = function(e)return(FALSE))

  # check if chosen variables are available in all models
  if(meteo_sw){
    if(any(is.na(var_names_dic[var_names_dic$Variable %in% meteo_names,]))){
      modl_fail <- colnames(var_names_dic)[colSums(is.na(var_names_dic[var_names_dic$Variable %in%
                                                                         meteo_names,])) > 0]
      vcar_fail <- meteo_names[is.na(var_names_dic[var_names_dic$Variable %in%
                                                     meteo_names,modl_fail])]
      stop(paste0("Meteorological variable ",vcar_fail," not available for scaling in model(s) ",
                  paste0(modl_fail,collapse = " & ")))
    }
  }

  ## needs to be changes to data
  #var_names_dic <- read.table("var_names_dic.csv",header = TRUE,sep=",",stringsAsFactors = FALSE)

  if(is.null(param_file)){
    ## Create Latin hypercube sample of parameters
    parRange <- matrix(c(par_lower,meteo_lower,par_upper,meteo_upper),
                       length(par_names) + length(meteo_names),2)
    params <- Latinhyper(parRange = as.matrix(parRange), num = num)
    params <- signif(params, 4)
    colnames(params) <- c(par_names,meteo_names)
    params <- as.data.frame(params)
    params$par_id <- paste0('p', formatC(1:nrow(params), width = 4, format = "d", flag = "0"))
    write.csv(params, file = file.path(folder, paste0('latin_hypercube_params_',
                                                      paste0(model, collapse = '_'),
                                                      '_', format(Sys.time(),
                                                                  format = '%Y%m%d%H%M'), '.csv')),
              quote = FALSE, row.names = FALSE)
  }else{
    params <- read.csv(param_file, stringsAsFactors = FALSE)
    num = nrow(params)
  }

  all_pars <- NULL
  all_sa <- NULL

  # FLake
  #####
  if('FLake' %in% model){
    fla_met <- met

    # Subset temporally
    fla_met <- fla_met[(fla_met[,1] >= start & fla_met[,1] < stop),]

    # Humidity
    if(!vapour_pressure & relative_humidity){
      # Calculate vapour pressure as: relhum * saturated vapour pressure
      # Used formula for saturated vapour pressure from:
      # Woolway, R. I., Jones, I. D., Hamilton, D. P., Maberly, S. C., Muraoka, K., Read, J. S., . . . Winslow, L. A. (2015).
      # Automated calculation of surface energy fluxes with high-frequency lake buoy data.
      # Environmental Modelling & Software, 70, 191-198.

      fla_met[[colname_vapour_pressure]] <- fla_met[[colname_relative_humidity]]/100 *
        6.11 * exp(17.27 * fla_met[[colname_air_temperature]] /
                     (237.3 + fla_met[[colname_air_temperature]]))

    }
    if(!cloud_cover){

      fla_met[[colname_cloud_cover]] =  calc_cc(date = fla_met$datetime,
                                                           airt = fla_met$Air_Temperature_celsius,
                                                           relh = fla_met$Relative_Humidity_percent,
                                                           swr = fla_met$Shortwave_Radiation_Downwelling_wattPerMeterSquared,
                                                           lat = lat, lon = lon,
                                                           elev = 14, # Needs to be added dynamically
                                                           daily = daily)

    }
    fla_met$index <- 1:nrow(fla_met)

    # Re-organise
    fla_met <- fla_met[,c('index','Shortwave_Radiation_Downwelling_wattPerMeterSquared',
                          'Air_Temperature_celsius', "Vapor_Pressure_milliBar",
                          "Ten_Meter_Elevation_Wind_Speed_meterPerSecond",
                          "Cloud_Cover_decimalFraction", "datetime")]
    fla_met$datetime <- format(fla_met$datetime, format = '%Y-%m-%d %H:%M:%S')
    colnames(fla_met)[1] <- paste0('!', colnames(fla_met)[1])

    # Select nml file for running FLake
    nml_file <- get_yaml_value(config_file, "config_files", "flake_config")
    nml_file <- file.path(folder, nml_file)
    # Select nml file again
    nml_file_run <- basename(get_yaml_value(config_file, "config_files", "flake_config"))

    mean_depth <- suppressWarnings(get_nml_value(arg_name = 'depth_w_lk', nml_file = nml_file))
    depths <- seq(0,mean_depth,by = get_yaml_value(config_file,"model_settings", "output_depths"))

    # Input values to nml
    nml_file <- list.files(file.path(folder, 'FLake'))[grep('nml', list.files(file.path(folder, 'FLake')))]
    nml_file <- file.path(folder, 'FLake', nml_file)

    input_nml(nml_file, 'SIMULATION_PARAMS', 'time_step_number', nrow(fla_met))
    input_nml(nml_file, 'METEO', 'meteofile', paste0("'",'temp_meteo_file.dat',"'"))

    for(i in 1:nrow(params)){
      if(meteo_sw){
        fla_met2 <- fla_met
        for (j in 1:length(meteo_names)) {
          met_name_fla <- var_names_dic$FLake[var_names_dic$Variable==meteo_names[j]]
          fla_met2[,met_name_fla] <- fla_met2[,met_name_fla] * params[i,meteo_names[j]]
        }

        # Write to file
        write.table(fla_met2, file.path(folder, 'FLake', 'temp_meteo_file.dat'), sep = '\t', quote = FALSE, col.names = FALSE, row.names = FALSE)
      }

      if(par_sw){
        # change parameter
      }
      run_flake(sim_folder = file.path(folder, 'FLake'), nml_file = nml_file_run)

      # Extract output
      # Add in obs depths which are not in depths and less than mean depth

      fla_long <- get_wtemp_df(output = file.path(folder, 'FLake', 'output', 'output.dat'), depths = depths, folder = 'FLake', nml_file = nml_file, long = TRUE)
      fla_wide <- get_wtemp_df(output = file.path(folder, 'FLake', 'output', 'output.dat'), depths = depths, folder = 'FLake', nml_file = nml_file, long = FALSE)

      stats <- sum_stat(fla_long, obs, depth = TRUE)
      stats$par_id <- params$par_id[i]

      # Calculate stats for Sensitivity Analysis
      sa_res <- analyse_strat(Ts = fla_wide[,2], Tb = fla_wide[,ncol(fla_wide)], dates = fla_wide[,1], NH = NH)
      sa_res$par_id <- params$par_id[i]


      if(i == 1){
        out_stats <- stats
        sa_stats <- sa_res
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
        sa_stats <- rbind.data.frame(sa_stats, sa_res)
      }
      print(paste0('[',i,'/', nrow(params),']'))
    }

    write.csv(out_stats, file.path(folder, 'Flake', 'output', paste0('latin_hypercube_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

    write.csv(sa_stats, file.path(folder, 'Flake', 'output', paste0('latin_hypercube_sa_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)


    out_stats$model <- 'FLake'
    sa_stats$model <- 'FLake'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }

    if(is.null(all_sa)){
      all_sa <- sa_stats
    }else{
      all_sa <- rbind.data.frame(all_sa, sa_stats)
    }


    message('FLake: Finished Latin Hypercube Sampling calibration')


  }

  # GLM
  #####
  if('GLM' %in% model){
    glm_met <- met

    # Convert units
    glm_met$Precipitation_meterPerDay <- glm_met$Precipitation_meterPerSecond * 86400

    # Subset data
    glm_met <- glm_met[,c('datetime','Shortwave_Radiation_Downwelling_wattPerMeterSquared',
                          "Longwave_Radiation_Downwelling_wattPerMeterSquared",
                          'Air_Temperature_celsius', 'Relative_Humidity_percent',
                          "Ten_Meter_Elevation_Wind_Speed_meterPerSecond",
                          "Precipitation_meterPerDay", "Snowfall_meterPerDay")]

    colnames(glm_met) <- c('Date','ShortWave','LongWave','AirTemp','RelHum','WindSpeed','Rain','Snow')
    glm_met[,1] <- format(glm_met[,1], format = '%Y-%m-%d %H:%M:%S')

    if("LongWave" %in% colnames(glm_met)){
      lw_type = 'LW_IN'
    }else{
      lw_type = 'LW_IN' ### Needs to be developed catch if no LW
    }

    # Input to nml file
    nml_path <- file.path(folder, get_yaml_value(config_file, "config_files", "glm_config"))
    nml <- glmtools::read_nml(nml_path)

    nml_list <- list('subdaily' = subdaily, 'lw_type' = lw_type, 'meteo_fl' = 'temp_meteo_file.csv')
    nml <- glmtools::set_nml(nml, arg_list = nml_list)

    glmtools::write_nml(nml, nml_path)

    # Input values to nml
    nml_file <- file.path(folder, 'GLM', 'glm3.nml')

    input_nml(nml_file, 'meteorology', 'meteo_fl', paste0("'",'temp_meteo_file.csv',"'"))

    # Get depths for comparison
    depths <- obs_deps

    for(i in 1:nrow(params)){
      if(meteo_sw){
        glm_met2 <- glm_met
        for (j in 1:length(meteo_names)) {
          met_name_glm <- var_names_dic$GLM[var_names_dic$Variable==meteo_names[j]]
          glm_met2[,met_name_glm] <- glm_met2[,met_name_glm] * params[i,meteo_names[j]]
        }

        # Write to file
        write.csv(glm_met2, file.path(folder, 'GLM', 'temp_meteo_file.csv'), quote = FALSE, row.names = FALSE)
      }
      if(par_sw){
        ## change parameter
      }
      run_glm(sim_folder = file.path(folder, 'GLM'))

      # Extract output
      # Add in obs depths which are not in depths and less than mean depth

      # Extract output
      glm_out <- glmtools::get_var(file = file.path(folder, 'GLM', 'output', 'output.nc'), var_name = 'temp', reference = 'surface', z_out = depths)

      glm_sa <- glmtools::get_var(file = file.path(folder, 'GLM', 'output', 'output.nc'), var_name = 'temp', reference = 'surface', z_out = c(0, depth-1))


      glm_out <- reshape2::melt(glm_out, id.vars = 1)
      glm_out[,2] <- as.character(glm_out[,2])
      glm_out[,2] <- as.numeric(gsub('temp_','',glm_out[,2]))
      colnames(glm_out) <- c('datetime','Depth_meter','Water_Temperature_celsius')

      stats <- sum_stat(glm_out, obs, depth = TRUE)
      stats$par_id <- params$par_id[i]

      # Calculate stats for Sensitivity Analysis
      sa_res <- analyse_strat(Ts = glm_sa[,2], Tb = glm_sa[,ncol(glm_sa)], dates = glm_sa[,1], NH = NH)

      sa_res$par_id <- params$par_id[i]


      if(i == 1){
        out_stats <- stats
        sa_stats <- sa_res
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
        sa_stats <- rbind.data.frame(sa_stats, sa_res)
      }
      print(paste0('[',i,'/', nrow(params),']'))
    }

    write.csv(out_stats, file.path(folder, 'GLM', 'output', paste0('latin_hypercube_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

    write.csv(sa_stats, file.path(folder, 'GLM', 'output', paste0('latin_hypercube_sa_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)


    out_stats$model <- 'GLM'
    sa_stats$model <- 'GLM'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }

    if(is.null(all_sa)){
      all_sa <- sa_stats
    }else{
      all_sa <- rbind.data.frame(all_sa, sa_stats)
    }

    message('GLM: Finished Latin Hypercube Sampling calibration')

  }

  ## GOTM
  if('GOTM' %in% model){

    met_got <- met
    yaml = file.path(folder,get_yaml_value(config_file, "config_files", "gotm_config"))

    met_outfile <- 'meteo_file_temp.dat'

    if(wind_direction){
      direction=270-met_got[[colname_wind_direction]] # Converting the wind direction to the "math" direction
      rads=direction/180*pi
      xcomp=met_got[[colname_wind_speed]]*cos(rads)
      ycomp=met_got[[colname_wind_speed]]*sin(rads)
      met_got$Uwind = xcomp
      met_got$Vwind = ycomp
    }else{
      met_got$Uwind_meterPerSecond = met_got[[colname_wind_speed]]
      met_got$Vwind_meterPerSecond = 0
    }

    if(!cloud_cover){
      # Function from gotmtools

      met_got$Cloud_Cover_decimalFraction <- calc_cc(date = met_got$datetime, airt = met_got$Air_Temperature_celsius, relh = met_got$Relative_Humidity_percent, swr = met_got$Shortwave_Radiation_Downwelling_wattPerMeterSquared, lat = lat, lon = lon,
                                                                elev = 14, # Needs to be dynamically added
                                                                daily = daily)
    }

    met_got <- met_got[,c('datetime', 'Uwind_meterPerSecond', 'Vwind_meterPerSecond', 'Surface_Level_Barometric_Pressure_pascal', 'Air_Temperature_celsius', 'Relative_Humidity_percent', 'Cloud_Cover_decimalFraction', 'Shortwave_Radiation_Downwelling_wattPerMeterSquared', 'Precipitation_meterPerSecond')]

    colnames(met_got)[1] <- paste0('!', colnames(met_got)[1])
    met_got[,1] <- format(met_got[,1], '%Y-%m-%d %H:%M:%S')

    #Reduce number of digits
    met_got[,-1] <- signif(met_got[,-1], digits = 8)



    # Format gotm.yaml file
    ## Set gotm.yaml met config
    ######
    #u10
    input_yaml(file = yaml, label = 'u10', key = 'file', value = met_outfile)
    input_yaml(file = yaml, label = 'u10', key = 'column', value = (which(colnames(met_got) == "Uwind_meterPerSecond")-1))
    input_yaml(file = yaml, label = 'u10', key = 'scale_factor', value = 1)
    #v10
    input_yaml(file = yaml, label = 'v10', key = 'file', value = met_outfile)
    input_yaml(file = yaml, label = 'v10', key = 'column', value = (which(colnames(met_got) == "Vwind_meterPerSecond")-1))
    input_yaml(file = yaml, label = 'v10', key = 'scale_factor', value = 1)
    #airp
    input_yaml(file = yaml, label = 'airp', key = 'file', value = met_outfile)
    input_yaml(file = yaml, label = 'airp', key = 'column', value = (which(colnames(met_got) == "Surface_Level_Barometric_Pressure_pascal" )-1))
    input_yaml(file = yaml, label = 'airp', key = 'scale_factor', value = 1)
    #airt
    input_yaml(file = yaml, label = 'airt', key = 'file', value = met_outfile)
    input_yaml(file = yaml, label = 'airt', key = 'column', value = (which(colnames(met_got) == "Air_Temperature_celsius")-1))
    input_yaml(file = yaml, label = 'airt', key = 'scale_factor', value = 1)
    #cloud
    input_yaml(file = yaml, label = 'cloud', key = 'file', value = met_outfile)
    input_yaml(file = yaml, label = 'cloud', key = 'column', value = (which(colnames(met_got) == "Cloud_Cover_decimalFraction" )-1))
    input_yaml(file = yaml, label = 'cloud', key = 'scale_factor', value = 1)
    #swr
    input_yaml(file = yaml, label = 'swr', key = 'file', value = met_outfile)
    input_yaml(file = yaml, label = 'swr', key = 'column', value = (which(colnames(met_got) == "Shortwave_Radiation_Downwelling_wattPerMeterSquared")-1))
    input_yaml(file = yaml, label = 'swr', key = 'scale_factor', value = 1)
    #precip
    input_yaml(file = yaml, label = 'precip', key = 'file', value = met_outfile)
    input_yaml(file = yaml, label = 'precip', key = 'column', value = (which(colnames(met_got) == "Precipitation_meterPerSecond")-1))
    input_yaml(file = yaml, label = 'precip', key = 'scale_factor', value = 1)
    if("Relative_Humidity_percent" %in% colnames(met_got)){
      #hum
      input_yaml(file = yaml, label = 'hum', key = 'file', value = met_outfile)
      input_yaml(file = yaml, label = 'hum', key = 'column', value = (which(colnames(met_got) == "Relative_Humidity_percent")-1))
      input_yaml(file = yaml, label = 'hum', key = 'type', value = 1) #1=relative humidity (%), 2=wet-bulb temperature, 3=dew point temperature, 4=specific humidity (kg/kg)
      input_yaml(file = yaml, label = 'hum', key = 'scale_factor', value = 1)
    }
    if("Dewpoint_Temperature_celsius" %in% colnames(met_got)){
      #hum
      input_yaml(file = yaml, label = 'hum', key = 'file', value = met_outfile)
      input_yaml(file = yaml, label = 'hum', key = 'column', value = (which(colnames(met_got) == "Dewpoint_Temperature_celsius")-1))
      input_yaml(file = yaml, label = 'hum', key = 'type', value = 3) #1=relative humidity (%), 2=wet-bulb temperature, 3=dew point temperature, 4=specific humidity (kg/kg)
      input_yaml(file = yaml, label = 'hum', key = 'scale_factor', value = 1)
    }

    # Get depths for comparison
    depths = -obs_deps
    obs_got <- obs
    obs_got[,2] <- -obs_got[,2]

    for(i in 1:nrow(params)){
      if(meteo_sw){
        got_met2 <- met_got
        for (j in 1:length(meteo_names)) {
          met_name_got <- var_names_dic$GOTM[var_names_dic$Variable==meteo_names[j]]
          got_met2[,met_name_got] <- got_met2[,met_name_got] * params[i,meteo_names[j]]
        }

        # Write to file
        write.table(got_met2, file.path('GOTM', met_outfile), quote = FALSE, row.names = FALSE, sep = '\t', col.names = TRUE)
      }

      if(par_sw){
        ## change parameter

      }

      yaml_file <- file.path(folder, get_yaml_value(config_file, "config_files", "gotm_config"))

      run_gotm(sim_folder = file.path(folder, 'GOTM'), yaml_file = basename(yaml_file))

      # Extract output
      # Add in obs depths which are not in depths and less than mean depth

      # Extract output
      temp <- get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'temp', print = FALSE)
      z <- get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'z', print = FALSE)


      got_out <- setmodDepths(temp, z, depths = depths, print = T)
      colnames(got_out) <- c('datetime','Depth_meter','Water_Temperature_celsius')

      stats <- sum_stat(got_out, obs_got, depth = TRUE)
      stats$par_id <- params$par_id[i]

      # Calculate stats for Sensitivity Analysis
      sa_res <- analyse_strat(Ts = temp[,2], Tb = temp[,ncol(temp)], dates =  temp[,1], NH = NH)

      sa_res$par_id <- params$par_id[i]


      if(i == 1){
        out_stats <- stats
        sa_stats <- sa_res
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
        sa_stats <- rbind.data.frame(sa_stats, sa_res)
      }

      print(paste0('[',i,'/', nrow(params),']'))
    }

    write.csv(out_stats, file.path(folder, 'GOTM', 'output',
                                   paste0('latin_hypercube_calibration_results_','p',num, '_',
                                          format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')),
              quote = FALSE, row.names = FALSE)

    write.csv(sa_stats, file.path(folder, 'GOTM', 'output',
                                  paste0('latin_hypercube_sa_results_','p',num, '_',
                                         format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')),
              quote = FALSE, row.names = FALSE)


    out_stats$model <- 'GOTM'
    sa_stats$model <- 'GOTM'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }

    if(is.null(all_sa)){
      all_sa <- sa_stats
    }else{
      all_sa <- rbind.data.frame(all_sa, sa_stats)
    }

    message('GOTM: Finished Latin Hypercube Sampling calibration')

  }

  ## Simstrat
  if('Simstrat' %in% model){

    par_file <- file.path(folder,get_yaml_value(config_file, "config_files", "simstrat_config"))
    met_sim <- met
    met_outfile <- 'meteo_file_temp.dat'

    # Required input file changes depending on the forcing mode in the config file
    forcing_mode <- get_json_value(par_file, "ModelConfig", "Forcing")

    ### Pre-processing
    # Time
    if(datetime){
      # Time in simstrat is in decimal days since a defined start year
      start_year <- get_json_value(par_file, "Simulation", "Start year")

      met_sim$datetime = as.numeric(difftime(met_sim$datetime,as.POSIXct(paste0(start_year,"-01-01")),units = "days"))
    }else{
      stop("Cannot find \"datetime\" column in the input file. Without this column, the model cannot run")
    }

    # Wind
    # If wind direction is provided, U and V wind components are calculated. If not, V wind is set to 0
    if(wind_direction){
      direction=270-met_sim[[colname_wind_direction]] # Converting the wind direction to the "math" direction
      rads=direction/180*pi
      xcomp=met_sim[[colname_wind_speed]]*cos(rads)
      ycomp=met_sim[[colname_wind_speed]]*sin(rads)
      met_sim$Uwind = xcomp
      met_sim$Vwind = ycomp
    }else{
      met_sim$Uwind_meterPerSecond = met_sim[[colname_wind_speed]]
      met_sim$Vwind_meterPerSecond = 0
    }

    # Humidity
    if(!vapour_pressure & relative_humidity){
      # Calculate vapour pressure as: relhum * saturated vapour pressure
      # Used formula for saturated vapour pressure from:
      # Woolway, R. I., Jones, I. D., Hamilton, D. P., Maberly, S. C., Muraoka, K., Read, J. S., . . . Winslow, L. A. (2015).
      # Automated calculation of surface energy fluxes with high-frequency lake buoy data.
      # Environmental Modelling & Software, 70, 191-198.

      met_sim[[colname_vapour_pressure]]=met_sim[[colname_relative_humidity]]/100 * 6.11 * exp(17.27 * met_sim[[colname_air_temperature]] / (237.3 + met_sim[[colname_air_temperature]]))

    }

    # If snow_module is true, there needs to be a precipitation (or snowfall) columnn.
    snow_module <- get_json_value(par_file, "ModelConfig", "SnowModel") == 1
    # Optionally, if there is no precipitation/snowfall column, we can set the snow_module to FALSE

    if(snow_module & !(precipitation | snowfall)){
      stop("There is no precipitation data and the Simstrat snow_module is set to TRUE.")
    }


    # Precipitation
    # Precipitation needs to be in m h-1: 1 m s-1 = 3600 m h-1, or 1 m d-1 = 1/24 m h-1
    if(precipitation){
      met_sim$`Precipitation_meterPerHour`=met_sim[[colname_precipitation]]*3600
    }else if(snowfall){
      met_sim$`Precipitation_meterPerHour`=met_sim[[colname_snow]]/24
    }




    ### Build simstrat_forcing file
    # Boolean to see if there is enough data to write the meteo file
    enoughData=T


    # Now build the simstrat forcing file, based on the forcing_mode. If data is not available, an error message is displayed
    if(forcing_mode == "5"){
      if(!(wind_speed & air_temperature & solar_radiation & (vapour_pressure | relative_humidity) & longwave_radiation)){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation, colname_vapour_pressure,
                                       colname_longwave_radiation)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }else if(forcing_mode == "4"){
      # Forcing mode 4 requires one column with "heat flux" input. LakeEnsemblR does not yet have functionality for this option
      enoughData = F
    }else if(forcing_mode == "3"){
      if(!(wind_speed & air_temperature & solar_radiation & (vapour_pressure | relative_humidity) & cloud_cover)){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation, colname_vapour_pressure,
                                       colname_cloud_cover)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }else if(forcing_mode == "2"){
      if(!(wind_speed & air_temperature & solar_radiation & (vapour_pressure | relative_humidity))){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation, colname_vapour_pressure)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }else if(forcing_mode == "1"){
      if(!(wind_speed & air_temperature & solar_radiation)){
        enoughData = F
      }else{
        simstrat_forcing = met_sim[, c(colname_time, "Uwind_meterPerSecond", "Vwind_meterPerSecond",
                                       colname_air_temperature, colname_solar_radiation)]
        if(snow_module){
          simstrat_forcing[["Precipitation_meterPerHour"]] = met_sim[["Precipitation_meterPerHour"]]
        }
      }
    }

    if(!enoughData){stop(paste("There is no data to run the model in forcing mode",forcing_mode))}

    input_json(file = par_file, label = 'Input', key = 'Forcing', paste0('"', met_outfile, '"'))

    # Need to input start and stop into json par file
    par_file <- file.path(folder, get_yaml_value(config_file, "config_files", "simstrat_config"))
    timestep <- get_json_value(par_file, "Simulation", "Timestep s")
    reference_year <- get_json_value(par_file, "Simulation", "Start year")

    # par file for running Simstrat
    par_file <- basename(get_yaml_value(config_file, "config_files", "simstrat_config"))


    for(i in 1:nrow(params)){

      if(meteo_sw){
        sim_met2 <- simstrat_forcing
        for (j in 1:length(meteo_names)) {
          met_name_sim <- var_names_dic$Simstrat[var_names_dic$Variable==meteo_names[j]]
          sim_met2[,met_name_sim] <- sim_met2[,met_name_sim] * params[i,meteo_names[j]]
        }
        # Write to file
        write.table(sim_met2, file = file.path(folder,"Simstrat", met_outfile),sep = "\t",quote = F,row.names = F)
      }

      if(par_sw){

        ## change parameter

      }
      run_simstrat(sim_folder = file.path(folder, 'Simstrat'), par_file = par_file, verbose = FALSE)

      ### Extract output
      sim_out <- read.table(file.path(folder, "Simstrat", "output", "T_out.dat"), header = T, sep=",", check.names = F)

      ### Convert decimal days to yyyy-mm-dd HH:MM:SS
      sim_out[,1] <- as.POSIXct(sim_out[,1]*3600*24, origin = paste0(reference_year,"-01-01"))
      # In case sub-hourly time steps are used, rounding might be necessary
      sim_out[,1] <- round_date(sim_out[,1], unit = seconds_to_period(timestep))

      # First column datetime, then depth from shallow to deep
      sim_out <- sim_out[,c(1,ncol(sim_out):2)]
      bot_ind <- which(!is.nan(colSums(sim_out[,-1])))
      bot_ind <- bot_ind[length(bot_ind)] + 1

      sim_sa <- sim_out[,c(1,2,bot_ind)]

      # Remove columns without any value
      sim_out <- sim_out[,colSums(is.na(sim_out))<nrow(sim_out)]
      mod_depths = as.numeric(colnames(sim_out)[-1])

      sim_depths <- -obs_deps
      message('Interpolating Simstrat temp to include obs depths')

      # Create empty matrix and interpolate to new depths
      wat_mat <- matrix(NA, nrow = nrow(sim_out), ncol = length(sim_depths))
      for(j in 1:nrow(sim_out)){
        y = as.vector(unlist(sim_out[j,-1]))
        wat_mat[j,] <- approx(mod_depths, y, sim_depths, rule = 2)$y
      }
      df = data.frame(wat_mat)
      df$datetime <- sim_out[,1]
      df <- df[,c(ncol(df), 1:(ncol(df)-1))]
      colnames(df) <- c("datetime", paste0('wtr_',abs(sim_depths)))
      sim_out <- df


      sim_out <- reshape2::melt(sim_out, id.vars = 1)
      sim_out[,2] <- as.character(sim_out[,2])
      sim_out[,2] <- as.numeric(gsub('wtr_','',sim_out[,2]))
      colnames(sim_out) <- c('datetime','Depth_meter','Water_Temperature_celsius')

      stats <- sum_stat(sim_out, obs, depth = TRUE)
      stats$par_id <- params$par_id[i]

      # Calculate stats for Sensitivity Analysis
      sa_res <- analyse_strat(Ts = sim_sa[,2], Tb = sim_sa[,3], dates =  sim_sa[,1], NH = NH)

      sa_res$par_id <- params$par_id[i]


      if(i == 1){
        out_stats <- stats
        sa_stats <- sa_res
      }else{
        out_stats <- rbind.data.frame(out_stats, stats)
        sa_stats <- rbind.data.frame(sa_stats, sa_res)
      }


      print(paste0('[',i,'/', nrow(params),']'))
    }




    ### Write the table in the present working directory
    write.csv(out_stats, file.path(folder, 'Simstrat', 'output', paste0('latin_hypercube_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

    write.csv(sa_stats, file.path(folder, 'Simstrat', 'output', paste0('latin_hypercube_sa_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)


    out_stats$model <- 'Simstrat'
    sa_stats$model <- 'Simstrat'

    if(is.null(all_pars)){
      all_pars <- out_stats
    }else{
      all_pars <- rbind.data.frame(all_pars, out_stats)
    }

    if(is.null(all_sa)){
      all_sa <- sa_stats
    }else{
      all_sa <- rbind.data.frame(all_sa, sa_stats)
    }

    message('Simstrat: Finished Latin Hypercube Sampling calibration')
  }

  dir.create(file.path(folder,'output'), showWarnings = FALSE)

  write.csv(all_pars, file.path(folder,'output', paste0('LHC_calibration_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

  write.csv(all_sa, file.path(folder,'output', paste0('LHC_sa_results_','p',num, '_', format(Sys.time(), format = '%Y%m%d%H%M'), '.csv')), quote = FALSE, row.names = FALSE)

}


