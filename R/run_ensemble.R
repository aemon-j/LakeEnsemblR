#' Run Ensemble of lake models
#'
#' Run each of the lake models
#'
#' @param config_file filepath; to LakeEnsemblr yaml master config file
#' @param model vector; model to export driving data. Options include
#'   c('GOTM', 'GLM', 'Simstrat', 'FLake', 'MyLake')
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param verbose Boolean; Should model output be shown in the console. Defaults to FALSE
#' @param parallel Boolean; should the model calibration be parallelized
#' @param return_list boolean; Return a list of dataframes of model output. Defaults to FALSE
#' @param create_output boolean; Create ensemble output file otherwise it just runs the models and generates model output in their respective folders. Defaults to TRUE
#' @param add boolean; Add results to an existing netcdf file with new dimension "member"
#' @importFrom parallel detectCores parLapply clusterExport makeCluster stopCluster clusterEvalQ
#' @importFrom gotmtools get_yaml_value get_vari
#' @importFrom reshape2 dcast
#' @importFrom glmtools get_nml_value get_var
#' @importFrom lubridate year round_date seconds_to_period
#'
#' @export
run_ensemble <- function(config_file, model = c("GOTM", "GLM", "Simstrat", "FLake", "MyLake"),
                         folder = ".", verbose = FALSE, parallel = FALSE,
                         return_list = FALSE, create_output = TRUE, add = FALSE){

  # check model input
  model <- check_models(model, check_package_install = TRUE)
  # check the master config file
  check_master_config(config_file, model)
  # It's advisable to set timezone to GMT in order to avoid errors when reading time
  original_tz  <-  Sys.getenv("TZ")
  Sys.setenv(TZ = "GMT")
  tz  <-  "UTC"

  # Set working directory
  oldwd <- getwd()

  # this way if the function exits for any reason, success or failure, these are reset:
  on.exit({
    setwd(oldwd)
    Sys.setenv(TZ = original_tz)
  })

  ## Extract start, stop, lat & lon for netCDF file from config file
  start <- get_yaml_value(config_file, "time", "start")
  stop <- get_yaml_value(config_file, "time", "stop")
  lat <- get_yaml_value(config_file, "location", "latitude")
  lon <- get_yaml_value(config_file, "location", "longitude")
  lakename <- get_yaml_value(config_file, "location", "name")
  obs_file <- get_yaml_value(config_file, "temperature", "file")
  ice_file <- get_yaml_value(config_file, "ice_height", "file")

  # Get output configurations
  out_file <- get_yaml_value(config_file, "output", "file")
  out_depths <- get_yaml_value(config_file, "output", "depths")
  format <- get_yaml_value(config_file, "output", "format")
  time_unit <- get_yaml_value(config_file, "output", "time_unit")
  if(time_unit == "second"){
    # Needed to create out_time vector
    time_unit <- "sec"
  }
  time_step <- get_yaml_value(config_file, "output", "time_step")
  out_vars <- get_yaml_value(config_file, "output", "variables")

  if(format == "netcdf") {
    out_file <- paste0(out_file, ".nc")
    compression <- get_yaml_value(config_file, "output", "compression")
  }


  # Create output time vector
  out_time <- data.frame(datetime = seq.POSIXt(as.POSIXct(start, tz = tz),
                                               as.POSIXct(stop, tz = tz),
                                               by = paste(time_step, time_unit)))


  if(!(obs_file == "NULL" | obs_file == "")){
    message("Loading water temperature observations...", paste0("[", Sys.time(), "]"))
    obs <- read.csv(obs_file, stringsAsFactors = FALSE)
    message("Finished loading water temperature observations!",
            paste0("[", Sys.time(), "]"))
    obs_deps <- unique(obs$Depth_meter)

    # change data format from long to wide
    obs_out <- reshape2::dcast(obs, datetime ~ Depth_meter, value.var = "Water_Temperature_celsius")
    str_depths <- colnames(obs_out)[2:ncol(obs_out)]
    colnames(obs_out) <- c("datetime", paste("wtr_", str_depths, sep = ""))
    obs_out$datetime <- as.POSIXct(obs_out$datetime, tz = tz)

    # Subset to out_time
    obs_out <- obs_out[obs_out$datetime %in% out_time$datetime, ]
    obs_out <- merge(out_time, obs_out, by = "datetime", all.x = TRUE)

  }else{
    obs_deps <- NULL
  }

  if(!(ice_file == "NULL" | ice_file == "")){
    message("Loading ice observations...")
    ice <- read.csv(ice_file, stringsAsFactors = FALSE)
    message("Finished loading ice observations!")

    ice$datetime <- as.POSIXct(ice$datetime, tz = tz)

    # Subset to out_time
    ice_out <- ice[ice$datetime %in% out_time$datetime, ]
    ice_out <- merge(out_time, ice_out, by = "datetime", all.x = TRUE)

  }else{
    ice_out <- NULL
  }


  run_model_args <- list(config_file = config_file,
                         folder = folder,
                         return_list = return_list,
                         create_output = create_output,
                         tz = tz,
                         start = start,
                         stop = stop,
                         verbose = verbose,
                         obs_deps = obs_deps,
                         out_time = out_time,
                         out_vars = out_vars,
                         time_step = time_step)

  if (parallel) {
    ncores <- parallel::detectCores() - 1
    clust <- parallel::makeCluster(ncores)
    parallel::clusterExport(clust, varlist = list("run_model_args"),
                  envir = environment())
    parallel::clusterEvalQ(clust, expr = {library(LakeEnsemblR); library(gotmtools);
      })
    message("Running models in parallel... ", paste0("[", Sys.time(), "]"))
    model_out <- setNames(
      parallel::parLapply(clust, model, function(mod_name) do.call(paste0(".run_", mod_name),
                                               run_model_args)),
      model
    )
    parallel::stopCluster(clust)
    message("Model run complete!", paste0("[", Sys.time(), "]"))

  } else {
    message("Running models... (Have you tried parallelizing?) ",
            paste0("[", Sys.time(), "]"))
    model_out <- setNames(
      lapply(model, function(mod_name) do.call(paste0(".run_", mod_name),
                                               run_model_args)),
      model
    )
    message("Model run complete!", paste0("[", Sys.time(), "]"))
  }


  if (return_list | create_output) {

    if("temp" %in% out_vars){
      temp_list <- setNames(
        lapply(model, function(mod_name) model_out[[mod_name]][["temp"]]),
        paste0(model, "_temp")
      )
      if(!is.null(obs_deps)){
        temp_list <- append(temp_list, list("Obs_temp" = obs_out))
      }
      # temp_list <- Filter(Negate(is.null), temp_list) # Remove NULL outputs
    }

    if("ice_height" %in% out_vars){
      ice_list <- setNames(
        lapply(model, function(mod_name) model_out[[mod_name]][["ice_height"]]),
        paste0(model, "_ice_height")
      )
      if(!is.null(ice_out)){
        ice_list <- append(ice_list, list("Obs_ice_height" = ice_out))
      }
    }

    if("dens" %in% out_vars){
      dens_list <- setNames(
        lapply(model, function(mod_name) model_out[[mod_name]][["dens"]]),
        paste0(model, "_dens")
      )
      # if(!is.null(obs_deps)){
      #   temp_list <- append(temp_list, list("Obs_temp" = obs_out))
      # }
      # temp_list <- Filter(Negate(is.null), temp_list) # Remove NULL outputs
    }

    if("salt" %in% out_vars){
      sal_list <- setNames(
        lapply(model, function(mod_name) model_out[[mod_name]][["salt"]]),
        paste0(model, "_salt")
      )
      # if(!is.null(obs_deps)){
      #   temp_list <- append(temp_list, list("Obs_temp" = obs_out))
      # }
      # temp_list <- Filter(Negate(is.null), temp_list) # Remove NULL outputs
    }

    # Put all lists with output into a single, named list
    all_lists <- NULL
    if(exists("temp_list")) all_lists[["temp_list"]] <- temp_list
    if(exists("ice_list")) all_lists[["ice_list"]] <- ice_list
    if(exists("dens_list")) all_lists[["dens_list"]] <- dens_list
    if(exists("sal_list")) all_lists[["sal_list"]] <- sal_list

    if(format == "netcdf") {
      if (!add & !file.exists(out_file)) {
        # Pass all_lists to the netcdf function to create netcdf output
        create_netcdf_output(output_lists = all_lists, folder = folder, model = model,
                             out_time = out_time, longitude = lon, latitude = lat,
                             compression = compression, out_file = out_file)
      } else {
        add_netcdf_output(output_lists = all_lists, folder = folder, model, out_file)
      }

    } else if (format == "text") { # Write to CSV

      out_dir <- file.path(folder, 'output')

      # Creat output directory
      if(!dir.exists(out_dir)) {
        message("Creating directory for output: ", file.path(folder, "output"))
        dir.create(out_dir, showWarnings = FALSE)
      }

      message("Writing '.csv' files... [", Sys.time(), "]")

      lapply(seq_len(length(all_lists)), function(x) {
        lapply(seq_len(length(all_lists[[x]])), function(y) {

          var_name <- strsplit(names(all_lists[[x]])[y], "_")[[1]][2]
          mod_name <- strsplit(names(all_lists[[x]])[y], "_")[[1]][1]

          out_fname <- file.path(out_dir, paste0(lakename, "_", mod_name,
                                                 "_", var_name, ".csv"))
          var <- all_lists[[x]][[y]]
          var[, -1] <- round(var[, -1], 2) # round to 2 digits to reduce filesize
          var[, 1] <- format(var[, 1], format = "%Y-%m-%d %H:%M:%S")

          write.csv(var , out_fname, row.names = FALSE, quote = FALSE)
        })
      })
      message("Finished writing '.csv' files! [", Sys.time(), "]")

    }
  }

  # Set the timezone back to the original
  Sys.setenv(TZ = original_tz)

  if(return_list){
    return(all_lists)
  }
}


#' @keywords internal
.run_GLM <- function(config_file, folder, return_list, create_output, tz, start, stop,
                     verbose, obs_deps, out_time, out_hour, out_vars, time_step){

  #Delete previous output
  # out_folder <- get_json_value(file = file.path(folder, par_fpath), label = 'Output', 'Path')
  old_output <- list.files(file.path(folder, "GLM", "output"))
  unlink(file.path(folder, "GLM", "output", old_output), recursive = TRUE)

  GLM3r::run_glm(sim_folder = file.path(folder, "GLM"), verbose = verbose)

  message("GLM run is complete! ", paste0("[", Sys.time(), "]"))

  if(return_list | create_output) {

    # Extract output
    glm_out <- get_output(config_file = config_file, model = "GLM", vars = out_vars,
                          obs_depths = obs_deps, folder = folder)

    # Ensure GLM is on the same time step for output
    if(!is.list(glm_out)) {
      glm_out <- merge(glm_out, out_time, by = "datetime", all.y = TRUE)
    } else {
      glm_out <- lapply(seq_len(length(glm_out)), function(x){
        merge(glm_out[[x]], out_time, by = 1, all.y = TRUE)
      })
      names(glm_out) <- out_vars # Re-assign names to list
    }

  }
  return(glm_out)
}

#' @keywords internal
#' @importFrom lubridate hour
.run_FLake <- function(config_file, folder, return_list, create_output, tz, start, stop,
                       verbose, obs_deps, out_time, out_hour, out_vars, time_step){



  nml_file <- basename(get_yaml_value(config_file, "config_files", "FLake"))

  #Delete previous output
  old_output <- list.files(file.path(folder, "FLake", "output"))
  unlink(file.path(folder, "FLake", "output", old_output), recursive = TRUE)


  FLakeR::run_flake(sim_folder = file.path(folder, "FLake"), nml_file = nml_file,
            verbose = verbose)

  if(return_list | create_output){

    met_timestep <- get_meteo_time_step(file.path(folder,
                                                  get_yaml_value(config_file, "meteo", "file")))
    out_hour <- ifelse(met_timestep == 86400, hour(start), 0) #Used for FLake output

    # Extract output
    fla_out <- get_output(config_file = config_file, model = "FLake", vars = out_vars,
                          obs_depths = obs_deps, folder = folder, out_time = out_time,
                          out_hour = out_hour)

    # Ensure FLake is on the same time step for output
    if(!is.list(fla_out)) {
      fla_out <- merge(fla_out, out_time, by = "datetime", all.y = TRUE)
    } else {
      fla_out <- lapply(seq_len(length(fla_out)), function(x){
        merge(fla_out[[x]], out_time, by = 1, all.y = TRUE)
      })
      names(fla_out) <- out_vars # Re-assign names to list
    }
  }
  message("FLake run is complete! ", paste0("[", Sys.time(), "]"))
  return(fla_out)

}

#' @keywords internal
.run_GOTM <- function(config_file, folder, return_list, create_output, tz, start, stop,
                      verbose, obs_deps,out_time, out_vars, time_step){

  yaml_file <- file.path(folder, get_yaml_value(config_file, "config_files", "GOTM"))

  #Delete previous output
  old_output <- list.files(file.path(folder, "GOTM", "output"))
  unlink(file.path(folder, "GOTM", "output", old_output), recursive = TRUE)

  GOTMr::run_gotm(sim_folder = file.path(folder, "GOTM"), yaml_file = basename(yaml_file),
           verbose = verbose)

  message("GOTM run is complete! ", paste0("[", Sys.time(), "]"))

  if(return_list | create_output){

    # Extract output
    gotm_out <- get_output(config_file = config_file, model = "GOTM", vars = out_vars,
                           obs_depths = obs_deps, folder = folder)

    # Ensure GOTM is on the same time step for output
    if(!is.list(gotm_out)) {
      gotm_out <- merge(gotm_out, out_time, by = "datetime", all.y = T)
    } else {
      gotm_out <- lapply(seq_len(length(gotm_out)), function(x){
        merge(gotm_out[[x]], out_time, by = 1, all.y = T)
      })
      names(gotm_out) <- out_vars # Re-assign names to list
    }
  }

  return(gotm_out)
}

#' @keywords internal
.run_Simstrat <- function(config_file, folder, return_list, create_output, tz, start, stop,
                          verbose, obs_deps, out_time, out_vars, time_step){

  par_file <- basename(get_yaml_value(config_file, "config_files", "Simstrat"))

  #Delete previous output
  # out_folder <- get_json_value(file = file.path(folder, par_fpath), label = "Output", "Path")
  old_output <- list.files(file.path(folder, "Simstrat", "output"))
  unlink(file.path(folder, "Simstrat", "output", old_output), recursive = TRUE)


  SimstratR::run_simstrat(sim_folder = file.path(folder, "Simstrat"), par_file = par_file, verbose = verbose)

  message("Simstrat run is complete! ", paste0("[", Sys.time(), "]"))

  if(return_list | create_output){

    ### Extract output
    sim_out <- get_output(config_file = config_file, model = "Simstrat", vars = out_vars,
                          obs_depths = obs_deps, folder = folder)

    # Ensure Simstrat is on the same time step for output
    if(!is.list(sim_out)) {
      sim_out <- merge(sim_out, out_time, by = "datetime", all.y = T)
    } else {
      sim_out <- lapply(seq_len(length(sim_out)), function(x){
        merge(sim_out[[x]], out_time, by = 1, all.y = T)
      })
      names(sim_out) <- out_vars # Re-assign names to list
    }
  }
  return(sim_out)
}

#' @keywords internal
.run_MyLake <- function(config_file, folder, return_list, create_output, tz, start, stop,
                        verbose, obs_deps, out_time, out_vars, time_step){

  cnfg_file <- gsub(".*/", "", gotmtools::get_yaml_value(config_file, "config_files", "MyLake"))
  MyLakeR::run_mylake(sim_folder = folder, config_dat = cnfg_file)

  message("MyLake run is complete! ", paste0("[", Sys.time(), "]"))

  if(return_list | create_output){

    ### Extract output
    mylake_out <- get_output(config_file = config_file, model = "MyLake", vars = out_vars,
                             obs_depths = obs_deps, folder = folder)

    if(!is.list(mylake_out)) {
      mylake_out <- merge(mylake_out, out_time, by = "datetime", all.y = T)
    } else {
      mylake_out <- lapply(seq_len(length(mylake_out)), function(x){
        merge(mylake_out[[x]], out_time, by = 1, all.y = T)
      })
      names(mylake_out) <- out_vars # Re-assign names to list
    }
  }
  return(mylake_out)
}
